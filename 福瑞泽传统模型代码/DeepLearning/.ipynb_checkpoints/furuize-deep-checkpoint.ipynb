{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anacoda\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mxnet import ndarray as nd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from mxnet import gluon as gl\n",
    "from mxnet import init\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd as ag\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import feature_selection\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CNN():\n",
    "    net = nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(\n",
    "            nn.Conv1D(channels = 16, kernel_size = 7, padding = 3),\n",
    "            nn.BatchNorm(axis = 1),\n",
    "            nn.Activation('relu'),\n",
    "#             nn.MaxPool1D(pool_size = 2, strides = 2),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv1D(channels=16, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm(axis=1),\n",
    "            nn.Activation('relu'),\n",
    "#             nn.MaxPool1D(pool_size = 2, strides = 2),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv1D(channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm(axis=1),\n",
    "            nn.Activation('relu'),\n",
    "#             nn.MaxPool1D(pool_size = 4, strides = 4),\n",
    "            nn.Dropout(0.1),\n",
    "        \n",
    "            nn.Conv1D(channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm(axis=1),\n",
    "            nn.Activation('relu'),\n",
    "#             nn.MaxPool1D(pool_size = 4, strides = 4),\n",
    "            nn.Dropout(0.2),\n",
    "        \n",
    "            nn.Conv1D(channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm(),\n",
    "            nn.Activation('relu'),\n",
    "#             nn.MaxPool1D(pool_size=4, strides=4),\n",
    "            nn.Dropout(0.2),\n",
    "#             nn.GlobalMaxPool1D(),\n",
    "            nn.Flatten(),\n",
    "            nn.Dense(2)\n",
    "        )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "\n",
    "def dataIter(X, y, batch_size, shuffle = True):\n",
    "    num_examples = y.shape[0]\n",
    "    index = list(range(num_examples))\n",
    "    if shuffle: random.shuffle(index)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = index[i: min(i + batch_size, num_examples)]\n",
    "        yield nd.array(X[j]), nd.array(y[j]), len(j)\n",
    "        \n",
    "def getWeight(params, label_pred, label_true):\n",
    "    weights = []\n",
    "    for pred, label in zip(label_pred, label_true):\n",
    "        tp_tn = (pred == label) * params['tp_tn_weight']\n",
    "        fp = ((pred == 0) * (label == 1)) * params['fp_weight']  \n",
    "        fn = ((pred == 1) * (label == 0)) * params['fn_weight']\n",
    "        weights.append(tp_tn + fp + fn)\n",
    "    return weights\n",
    "\n",
    "def testDataIter(X, batch_size):\n",
    "    num_examples = X.shape[0]\n",
    "    index = list(range(num_examples))\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = index[i: min(i + batch_size, num_examples)]\n",
    "        yield nd.array(X[j])\n",
    "        \n",
    "def accuracy(output, label):\n",
    "    return nd.sum(output.argmax(axis = 1) == label).asscalar()\n",
    "\n",
    "def testAccuracy(net, ctx, X, y):\n",
    "    acc = 0.\n",
    "    pred_labels = []\n",
    "    pred_probs = []\n",
    "    index = 0\n",
    "    for data, label, bs in dataIter(X, y, 64, shuffle = False):\n",
    "        data = nd.array(data).as_in_context(ctx)\n",
    "        label = nd.array(label).as_in_context(ctx)\n",
    "        output = net(data) # the size of output is (64,2)\n",
    "        output = nd.softmax(output, axis = 1)   # the size of output is (64,2)\n",
    "        pred_label = nd.argmax(output, axis = 1) # the size of pre_label is (64,)\n",
    "        pred_prob = output[:, 0] \n",
    "        pred_labels.append(pred_label)\n",
    "        pred_probs.append(pred_prob)\n",
    "        index += bs\n",
    "        \n",
    "        predict = nd.sum(pred_label == label).asscalar()\n",
    "        acc += predict\n",
    "        \n",
    "    pred_labels = nd.concatenate(pred_labels, axis = 0).asnumpy()\n",
    "    pred_probs = nd.concatenate(pred_probs, axis = 0).asnumpy()\n",
    "    return acc / y.shape[0] * 100, pred_labels, pred_probs\n",
    "\n",
    "def testProb(net, ctx, X):\n",
    "    pred_labels = []\n",
    "    pred_probs = []\n",
    "    for data in testDataIter(X, 64):\n",
    "        data = nd.array(data).as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        output = nd.softmax(output, axis = 1)\n",
    "        pred_label = nd.argmax(output, axis = 1)\n",
    "        pred_prob = output[:, 0]\n",
    "        pred_labels.append(pred_label)\n",
    "        pred_probs.append(pred_prob)\n",
    "    \n",
    "    pred_labels = nd.concatenate(pred_labels, axis = 0).asnumpy()\n",
    "    pred_probs = nd.concatenate(pred_probs, axis = 0).asnumpy()\n",
    "    print(pred_labels, pred_prob)\n",
    "    return pred_labels, pred_probs\n",
    "\n",
    "def calculateLoss(params, net, loss_fuc, ctx, X, y):\n",
    "    total_loss = 0.\n",
    "    for data, label, bs in dataIter(X, y, 64, shuffle = False):\n",
    "        data = nd.array(data).as_in_context(ctx)\n",
    "        label = nd.array(label).as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        weight = getWeight(params, [nd.argmax(output, axis = 1)], [label])[0]\n",
    "        loss = loss_fuc(output, label, weight)\n",
    "        total_loss += nd.sum(loss).asscalar()\n",
    "    return total_loss / y.shape[0]\n",
    "\n",
    "def plotConfusionMatrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "def evaluate(test_y, test_pred_label, test_pred_prob, pos_label = 0):\n",
    "    auc = calculateAUC(test_y, test_pred_prob, pos_label = pos_label)\n",
    "    ks_their, ks_mine = calculateKS(test_y, test_pred_prob)\n",
    "    cm = metrics.confusion_matrix(test_y, test_pred_label)\n",
    "#     plotConfusionMatrix(cm, ['good', 'bad'])\n",
    "    return auc, ks_their, ks_mine\n",
    "\n",
    "def calculateAUC(label, prob, pos_label):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label, prob, pos_label = pos_label)  \n",
    "    ks = max(tpr - fpr)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc\n",
    "\n",
    "def calculateKS(label, prob):\n",
    "    df = pd.DataFrame(data = {'label': label, 'prob': prob})\n",
    "    df['prob'] = df['prob'].map(lambda x: round(x, 3))\n",
    "    total = pd.DataFrame({'total': df.groupby('prob')['label'].count()})  \n",
    "    bad = pd.DataFrame({'bad': df.groupby('prob')['label'].sum()})\n",
    "    all_data = total.merge(bad, how = 'left', left_index = True, right_index = True)\n",
    "    all_data['good'] = all_data['total'] - all_data['bad']\n",
    "    all_data.reset_index(inplace = True)\n",
    "    all_data.sort_index(ascending = False, inplace = True)\n",
    "    all_data['goodCumPer'] = all_data['good'].cumsum() / all_data['good'].sum()\n",
    "    all_data['badCumPer'] = all_data['bad'].cumsum() / all_data['bad'].sum()\n",
    "    KS_m = all_data.apply(lambda x: x.goodCumPer - x.badCumPer, axis = 1)\n",
    "    KS_t = all_data.apply(lambda x: x.badCumPer - x.goodCumPer, axis = 1)\n",
    "    return max(KS_t), max(KS_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(fold, train_X, train_y, valid_X, valid_y, test_X, test_y, params):\n",
    "    ctx = [mx.gpu(i) for i in params['ctx']]\n",
    "    net = params['model']()\n",
    "    net.initialize(ctx = ctx, init = init.Xavier())\n",
    "    trainer = gl.Trainer(net.collect_params(), params['optimizer'], {'learning_rate': params['lr'], \n",
    "                                                                     'wd': params['wd']})\n",
    "    loss = gl.loss.SoftmaxCrossEntropyLoss()\n",
    "    \n",
    "    keep_indicator = -1\n",
    "\n",
    "    for epoch in range(1, params['epochs'] + 1):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for data, label, bs in dataIter(train_X, train_y, params['bs']):\n",
    "            data = gl.utils.split_and_load(data, ctx)\n",
    "            label = gl.utils.split_and_load(label, ctx)\n",
    "            with ag.record():\n",
    "                outputs = [net(x) for x in data]\n",
    "                label_preds = [nd.argmax(nd.softmax(output, axis = 1), axis = 1) for output in outputs]\n",
    "                weights = getWeight(params, label_preds, label)\n",
    "                losses = [loss(x, y, z) for x, y, z in zip(outputs, label, weights)]\n",
    "            for l in losses: l.backward()\n",
    "            \n",
    "            trainer.step(params['bs'])\n",
    "            train_loss += sum([l.sum().asscalar() for l in losses])\n",
    "            train_acc += sum([accuracy(x, y) for x, y in zip(outputs, label)])\n",
    "        trainer.set_learning_rate(params['lr'] - params['lr'] / params['epochs'] * epoch)\n",
    "        \n",
    "        _, train_pred_label, train_pred_prob = testAccuracy(net, ctx[0], train_X, train_y)\n",
    "        train_auc, train_ks_their, train_ks_mine = \\\n",
    "        evaluate(train_y, train_pred_label, train_pred_prob, pos_label = 0)\n",
    "        \n",
    "        valid_loss = calculateLoss(params, net, loss, ctx[0], valid_X, valid_y)\n",
    "        valid_acc, valid_pred_label, valid_pred_prob = testAccuracy(net, ctx[0], valid_X, valid_y)\n",
    "        valid_auc, valid_ks_their, valid_ks_mine = \\\n",
    "        evaluate(valid_y, valid_pred_label, valid_pred_prob, pos_label = 0)\n",
    "        \n",
    "        test_loss = calculateLoss(params, net, loss, ctx[0], test_X, test_y)\n",
    "        test_acc, test_pred_label, test_pred_prob = testAccuracy(net, ctx[0], test_X, test_y)\n",
    "        test_auc, test_ks_their, test_ks_mine = evaluate(test_y, test_pred_label, test_pred_prob, pos_label = 0)\n",
    "        \n",
    "        f1 = valid_auc * valid_ks_mine / (valid_auc + valid_ks_mine) \n",
    "        if f1 > keep_indicator:\n",
    "            keep_indicator = f1\n",
    "            net.save_params(params['model_path'] + '%s-%d-fold.model' % (params['prefix'], fold))\n",
    "        \n",
    "        print(\"%3d. L: %.3f,Acc %.1f,AUC %.3f,KS %.3f|\"\n",
    "                   \"L: %.3f,Acc %.1f,AUC %.3f,KS %.3f|\"\n",
    "                   \"L: %.3f,Acc %.1f,AUC %.3f,KS %.3f\" %\n",
    "              (epoch, train_loss / train_X.shape[0], train_acc / train_X.shape[0] * 100, train_auc, train_ks_mine,\n",
    "               valid_loss, valid_acc, valid_auc, valid_ks_mine, \n",
    "               test_loss, test_acc, test_auc, test_ks_mine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(fold, params, X, y):\n",
    "    ctx = [mx.gpu(i) for i in params['ctx']][0]\n",
    "    net = params['model']()\n",
    "    net.load_params(params['model_path'] + '%s-%d-fold.model' % (params['prefix'], fold), ctx = ctx)\n",
    "\n",
    "    acc, pred_label, pred_prob = testAccuracy(net, ctx, X, y)\n",
    "    auc, ks_their, ks_mine = evaluate(y, pred_label, pred_prob, pos_label = 0)\n",
    "    return auc, ks_mine, pred_prob\n",
    "\n",
    "def blindPredict(params, X):\n",
    "    ctx = [mx.gpu(i) for i in params['ctx']][0]\n",
    "    net = params['model']()\n",
    "    net.load_params(params['model_path'], ctx = ctx)\n",
    "\n",
    "    pred_label, pred_prob = testProb(net, ctx, X)\n",
    "    return pred_label, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(79054, 122) (79054,)\n",
      "After feature delete:  (79054, 122)\n",
      "After Sample delete: (79054, 122)\n",
      "After Feature Selection:  (79054, 122) (79054,)\n",
      "fold 1\n",
      "  1. L: 0.105,Acc 99.0,AUC 0.706,KS 0.304|L: 0.052,Acc 99.3,AUC 0.710,KS 0.319|L: 0.061,Acc 99.1,AUC 0.699,KS 0.315\n",
      "  2. L: 0.062,Acc 99.1,AUC 0.764,KS 0.397|L: 0.048,Acc 99.3,AUC 0.728,KS 0.387|L: 0.057,Acc 99.2,AUC 0.720,KS 0.349\n",
      "  3. L: 0.057,Acc 99.1,AUC 0.779,KS 0.423|L: 0.049,Acc 99.3,AUC 0.742,KS 0.369|L: 0.057,Acc 99.2,AUC 0.731,KS 0.368\n",
      "  4. L: 0.055,Acc 99.1,AUC 0.791,KS 0.444|L: 0.046,Acc 99.3,AUC 0.761,KS 0.402|L: 0.057,Acc 99.2,AUC 0.725,KS 0.371\n",
      "  5. L: 0.055,Acc 99.1,AUC 0.790,KS 0.435|L: 0.047,Acc 99.3,AUC 0.745,KS 0.376|L: 0.056,Acc 99.2,AUC 0.749,KS 0.391\n",
      "  6. L: 0.054,Acc 99.1,AUC 0.794,KS 0.438|L: 0.048,Acc 99.3,AUC 0.748,KS 0.387|L: 0.057,Acc 99.1,AUC 0.747,KS 0.393\n",
      "  7. L: 0.054,Acc 99.1,AUC 0.797,KS 0.447|L: 0.047,Acc 99.3,AUC 0.741,KS 0.401|L: 0.057,Acc 99.2,AUC 0.737,KS 0.361\n",
      "  8. L: 0.053,Acc 99.1,AUC 0.806,KS 0.469|L: 0.047,Acc 99.3,AUC 0.767,KS 0.430|L: 0.058,Acc 99.1,AUC 0.759,KS 0.419\n",
      "  9. L: 0.054,Acc 99.1,AUC 0.807,KS 0.471|L: 0.047,Acc 99.3,AUC 0.771,KS 0.420|L: 0.056,Acc 99.2,AUC 0.755,KS 0.414\n",
      " 10. L: 0.055,Acc 99.1,AUC 0.813,KS 0.485|L: 0.048,Acc 99.3,AUC 0.774,KS 0.439|L: 0.060,Acc 99.1,AUC 0.756,KS 0.410\n",
      " 11. L: 0.053,Acc 99.1,AUC 0.811,KS 0.482|L: 0.047,Acc 99.3,AUC 0.770,KS 0.417|L: 0.059,Acc 99.1,AUC 0.763,KS 0.444\n",
      " 12. L: 0.052,Acc 99.1,AUC 0.814,KS 0.485|L: 0.047,Acc 99.3,AUC 0.771,KS 0.408|L: 0.059,Acc 99.1,AUC 0.744,KS 0.435\n",
      " 13. L: 0.052,Acc 99.1,AUC 0.820,KS 0.495|L: 0.047,Acc 99.3,AUC 0.779,KS 0.437|L: 0.057,Acc 99.2,AUC 0.742,KS 0.411\n",
      " 14. L: 0.053,Acc 99.1,AUC 0.819,KS 0.477|L: 0.048,Acc 99.3,AUC 0.769,KS 0.378|L: 0.058,Acc 99.2,AUC 0.744,KS 0.404\n",
      " 15. L: 0.052,Acc 99.1,AUC 0.826,KS 0.508|L: 0.046,Acc 99.3,AUC 0.773,KS 0.441|L: 0.055,Acc 99.2,AUC 0.762,KS 0.424\n",
      " 16. L: 0.052,Acc 99.2,AUC 0.822,KS 0.485|L: 0.046,Acc 99.3,AUC 0.771,KS 0.414|L: 0.055,Acc 99.2,AUC 0.767,KS 0.433\n",
      " 17. L: 0.052,Acc 99.1,AUC 0.825,KS 0.499|L: 0.047,Acc 99.3,AUC 0.784,KS 0.432|L: 0.055,Acc 99.2,AUC 0.765,KS 0.419\n",
      " 18. L: 0.051,Acc 99.2,AUC 0.825,KS 0.487|L: 0.047,Acc 99.3,AUC 0.777,KS 0.458|L: 0.055,Acc 99.2,AUC 0.762,KS 0.470\n",
      " 19. L: 0.051,Acc 99.1,AUC 0.836,KS 0.512|L: 0.047,Acc 99.3,AUC 0.767,KS 0.387|L: 0.058,Acc 99.1,AUC 0.742,KS 0.368\n",
      " 20. L: 0.051,Acc 99.2,AUC 0.839,KS 0.528|L: 0.046,Acc 99.3,AUC 0.782,KS 0.431|L: 0.056,Acc 99.2,AUC 0.759,KS 0.415\n",
      " 21. L: 0.050,Acc 99.1,AUC 0.844,KS 0.531|L: 0.047,Acc 99.3,AUC 0.763,KS 0.390|L: 0.057,Acc 99.1,AUC 0.753,KS 0.425\n",
      " 22. L: 0.050,Acc 99.1,AUC 0.841,KS 0.525|L: 0.047,Acc 99.3,AUC 0.790,KS 0.460|L: 0.057,Acc 99.2,AUC 0.754,KS 0.424\n",
      " 23. L: 0.050,Acc 99.1,AUC 0.845,KS 0.531|L: 0.047,Acc 99.3,AUC 0.790,KS 0.449|L: 0.057,Acc 99.1,AUC 0.760,KS 0.415\n",
      " 24. L: 0.051,Acc 99.1,AUC 0.847,KS 0.530|L: 0.046,Acc 99.3,AUC 0.783,KS 0.420|L: 0.056,Acc 99.2,AUC 0.758,KS 0.410\n",
      " 25. L: 0.050,Acc 99.2,AUC 0.850,KS 0.541|L: 0.046,Acc 99.3,AUC 0.787,KS 0.443|L: 0.057,Acc 99.2,AUC 0.755,KS 0.416\n",
      " 26. L: 0.049,Acc 99.1,AUC 0.853,KS 0.540|L: 0.046,Acc 99.3,AUC 0.790,KS 0.436|L: 0.057,Acc 99.2,AUC 0.735,KS 0.363\n",
      " 27. L: 0.050,Acc 99.1,AUC 0.858,KS 0.563|L: 0.047,Acc 99.3,AUC 0.774,KS 0.413|L: 0.057,Acc 99.1,AUC 0.746,KS 0.385\n",
      " 28. L: 0.049,Acc 99.2,AUC 0.857,KS 0.544|L: 0.049,Acc 99.3,AUC 0.784,KS 0.411|L: 0.057,Acc 99.1,AUC 0.748,KS 0.398\n",
      " 29. L: 0.049,Acc 99.1,AUC 0.857,KS 0.553|L: 0.049,Acc 99.3,AUC 0.785,KS 0.468|L: 0.059,Acc 99.1,AUC 0.757,KS 0.397\n",
      " 30. L: 0.049,Acc 99.1,AUC 0.861,KS 0.556|L: 0.046,Acc 99.3,AUC 0.797,KS 0.489|L: 0.057,Acc 99.1,AUC 0.751,KS 0.386\n",
      " 31. L: 0.049,Acc 99.2,AUC 0.856,KS 0.541|L: 0.047,Acc 99.3,AUC 0.790,KS 0.467|L: 0.057,Acc 99.2,AUC 0.741,KS 0.353\n",
      " 32. L: 0.049,Acc 99.1,AUC 0.863,KS 0.560|L: 0.048,Acc 99.3,AUC 0.782,KS 0.441|L: 0.060,Acc 99.1,AUC 0.747,KS 0.374\n",
      " 33. L: 0.049,Acc 99.2,AUC 0.860,KS 0.559|L: 0.046,Acc 99.3,AUC 0.785,KS 0.447|L: 0.056,Acc 99.2,AUC 0.749,KS 0.372\n",
      " 34. L: 0.048,Acc 99.2,AUC 0.865,KS 0.563|L: 0.047,Acc 99.3,AUC 0.786,KS 0.460|L: 0.057,Acc 99.1,AUC 0.738,KS 0.341\n",
      " 35. L: 0.049,Acc 99.2,AUC 0.852,KS 0.520|L: 0.048,Acc 99.3,AUC 0.793,KS 0.465|L: 0.057,Acc 99.2,AUC 0.750,KS 0.406\n",
      " 36. L: 0.048,Acc 99.2,AUC 0.870,KS 0.570|L: 0.047,Acc 99.3,AUC 0.790,KS 0.505|L: 0.060,Acc 99.1,AUC 0.733,KS 0.333\n",
      " 37. L: 0.048,Acc 99.1,AUC 0.873,KS 0.576|L: 0.048,Acc 99.3,AUC 0.784,KS 0.445|L: 0.059,Acc 99.1,AUC 0.715,KS 0.284\n",
      " 38. L: 0.048,Acc 99.2,AUC 0.867,KS 0.560|L: 0.048,Acc 99.3,AUC 0.789,KS 0.487|L: 0.057,Acc 99.1,AUC 0.747,KS 0.358\n",
      " 39. L: 0.047,Acc 99.2,AUC 0.863,KS 0.542|L: 0.047,Acc 99.3,AUC 0.794,KS 0.459|L: 0.056,Acc 99.2,AUC 0.747,KS 0.393\n",
      " 40. L: 0.048,Acc 99.2,AUC 0.868,KS 0.556|L: 0.048,Acc 99.3,AUC 0.793,KS 0.476|L: 0.057,Acc 99.1,AUC 0.745,KS 0.373\n",
      " 41. L: 0.048,Acc 99.2,AUC 0.868,KS 0.553|L: 0.047,Acc 99.3,AUC 0.788,KS 0.488|L: 0.057,Acc 99.1,AUC 0.742,KS 0.380\n",
      " 42. L: 0.048,Acc 99.2,AUC 0.879,KS 0.582|L: 0.048,Acc 99.3,AUC 0.782,KS 0.456|L: 0.059,Acc 99.1,AUC 0.723,KS 0.308\n",
      " 43. L: 0.048,Acc 99.2,AUC 0.879,KS 0.585|L: 0.048,Acc 99.3,AUC 0.785,KS 0.461|L: 0.060,Acc 99.1,AUC 0.726,KS 0.339\n",
      " 44. L: 0.048,Acc 99.2,AUC 0.879,KS 0.581|L: 0.049,Acc 99.3,AUC 0.787,KS 0.455|L: 0.059,Acc 99.1,AUC 0.724,KS 0.320\n",
      " 45. L: 0.047,Acc 99.2,AUC 0.872,KS 0.559|L: 0.047,Acc 99.3,AUC 0.786,KS 0.470|L: 0.058,Acc 99.1,AUC 0.730,KS 0.354\n",
      " 46. L: 0.048,Acc 99.2,AUC 0.879,KS 0.579|L: 0.048,Acc 99.3,AUC 0.787,KS 0.476|L: 0.058,Acc 99.1,AUC 0.726,KS 0.309\n",
      " 47. L: 0.047,Acc 99.2,AUC 0.866,KS 0.550|L: 0.048,Acc 99.3,AUC 0.784,KS 0.457|L: 0.057,Acc 99.2,AUC 0.744,KS 0.399\n",
      " 48. L: 0.047,Acc 99.2,AUC 0.874,KS 0.570|L: 0.048,Acc 99.3,AUC 0.788,KS 0.475|L: 0.058,Acc 99.1,AUC 0.733,KS 0.350\n",
      " 49. L: 0.047,Acc 99.2,AUC 0.877,KS 0.579|L: 0.048,Acc 99.3,AUC 0.783,KS 0.467|L: 0.058,Acc 99.1,AUC 0.731,KS 0.347\n",
      " 50. L: 0.047,Acc 99.2,AUC 0.875,KS 0.575|L: 0.048,Acc 99.3,AUC 0.786,KS 0.468|L: 0.058,Acc 99.1,AUC 0.732,KS 0.338\n",
      "Valid AUC: 0.790, Valid KS: 0.505\n",
      "Test AUC: 0.733, Test KS: 0.333\n",
      "fold 2\n",
      "  1. L: 0.104,Acc 99.0,AUC 0.758,KS 0.376|L: 0.054,Acc 99.2,AUC 0.755,KS 0.384|L: 0.285,Acc 99.2,AUC 0.699,KS 0.309\n",
      "  2. L: 0.059,Acc 99.1,AUC 0.781,KS 0.417|L: 0.059,Acc 99.2,AUC 0.761,KS 0.394|L: 0.318,Acc 99.2,AUC 0.724,KS 0.350\n",
      "  3. L: 0.056,Acc 99.1,AUC 0.777,KS 0.436|L: 0.052,Acc 99.2,AUC 0.742,KS 0.365|L: 0.247,Acc 99.2,AUC 0.691,KS 0.286\n",
      "  4. L: 0.056,Acc 99.1,AUC 0.793,KS 0.438|L: 0.053,Acc 99.2,AUC 0.746,KS 0.372|L: 0.266,Acc 99.2,AUC 0.726,KS 0.376\n",
      "  5. L: 0.054,Acc 99.2,AUC 0.792,KS 0.432|L: 0.055,Acc 99.2,AUC 0.752,KS 0.407|L: 0.287,Acc 99.2,AUC 0.727,KS 0.344\n",
      "  6. L: 0.054,Acc 99.2,AUC 0.816,KS 0.479|L: 0.052,Acc 99.2,AUC 0.770,KS 0.393|L: 0.267,Acc 99.1,AUC 0.723,KS 0.365\n",
      "  7. L: 0.053,Acc 99.2,AUC 0.814,KS 0.470|L: 0.051,Acc 99.2,AUC 0.772,KS 0.419|L: 0.246,Acc 99.1,AUC 0.712,KS 0.364\n",
      "  8. L: 0.052,Acc 99.2,AUC 0.810,KS 0.475|L: 0.051,Acc 99.2,AUC 0.769,KS 0.385|L: 0.246,Acc 99.1,AUC 0.725,KS 0.376\n",
      "  9. L: 0.052,Acc 99.2,AUC 0.823,KS 0.499|L: 0.052,Acc 99.2,AUC 0.767,KS 0.398|L: 0.262,Acc 99.1,AUC 0.751,KS 0.385\n",
      " 10. L: 0.052,Acc 99.2,AUC 0.819,KS 0.480|L: 0.050,Acc 99.2,AUC 0.783,KS 0.415|L: 0.244,Acc 99.2,AUC 0.738,KS 0.390\n",
      " 11. L: 0.052,Acc 99.2,AUC 0.820,KS 0.484|L: 0.051,Acc 99.2,AUC 0.773,KS 0.404|L: 0.242,Acc 99.1,AUC 0.727,KS 0.379\n",
      " 12. L: 0.051,Acc 99.2,AUC 0.824,KS 0.494|L: 0.051,Acc 99.2,AUC 0.775,KS 0.414|L: 0.259,Acc 99.1,AUC 0.735,KS 0.409\n",
      " 13. L: 0.052,Acc 99.2,AUC 0.819,KS 0.486|L: 0.053,Acc 99.2,AUC 0.746,KS 0.415|L: 0.266,Acc 99.1,AUC 0.749,KS 0.409\n",
      " 14. L: 0.051,Acc 99.2,AUC 0.839,KS 0.516|L: 0.052,Acc 99.2,AUC 0.767,KS 0.439|L: 0.267,Acc 99.2,AUC 0.734,KS 0.364\n",
      " 15. L: 0.051,Acc 99.2,AUC 0.841,KS 0.527|L: 0.052,Acc 99.2,AUC 0.777,KS 0.418|L: 0.264,Acc 99.1,AUC 0.734,KS 0.426\n",
      " 16. L: 0.050,Acc 99.2,AUC 0.840,KS 0.526|L: 0.051,Acc 99.2,AUC 0.772,KS 0.418|L: 0.256,Acc 99.1,AUC 0.732,KS 0.379\n",
      " 17. L: 0.050,Acc 99.2,AUC 0.837,KS 0.509|L: 0.051,Acc 99.2,AUC 0.757,KS 0.413|L: 0.260,Acc 99.1,AUC 0.740,KS 0.399\n",
      " 18. L: 0.050,Acc 99.2,AUC 0.847,KS 0.534|L: 0.052,Acc 99.2,AUC 0.750,KS 0.379|L: 0.234,Acc 99.1,AUC 0.725,KS 0.361\n",
      " 19. L: 0.053,Acc 99.1,AUC 0.837,KS 0.532|L: 0.053,Acc 99.2,AUC 0.759,KS 0.398|L: 0.260,Acc 99.1,AUC 0.738,KS 0.404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20. L: 0.050,Acc 99.1,AUC 0.846,KS 0.538|L: 0.052,Acc 99.2,AUC 0.757,KS 0.383|L: 0.263,Acc 99.1,AUC 0.726,KS 0.365\n",
      " 21. L: 0.050,Acc 99.2,AUC 0.852,KS 0.541|L: 0.052,Acc 99.2,AUC 0.761,KS 0.392|L: 0.258,Acc 99.1,AUC 0.723,KS 0.355\n",
      " 22. L: 0.050,Acc 99.2,AUC 0.838,KS 0.517|L: 0.052,Acc 99.2,AUC 0.771,KS 0.395|L: 0.270,Acc 99.2,AUC 0.725,KS 0.393\n",
      " 23. L: 0.049,Acc 99.2,AUC 0.853,KS 0.547|L: 0.054,Acc 99.2,AUC 0.762,KS 0.373|L: 0.283,Acc 99.1,AUC 0.723,KS 0.361\n",
      " 24. L: 0.049,Acc 99.2,AUC 0.859,KS 0.552|L: 0.052,Acc 99.2,AUC 0.747,KS 0.350|L: 0.248,Acc 99.1,AUC 0.728,KS 0.336\n",
      " 25. L: 0.049,Acc 99.2,AUC 0.850,KS 0.537|L: 0.051,Acc 99.2,AUC 0.761,KS 0.382|L: 0.252,Acc 99.1,AUC 0.731,KS 0.369\n",
      " 26. L: 0.049,Acc 99.2,AUC 0.861,KS 0.558|L: 0.053,Acc 99.2,AUC 0.753,KS 0.386|L: 0.263,Acc 99.1,AUC 0.729,KS 0.375\n",
      " 27. L: 0.049,Acc 99.2,AUC 0.866,KS 0.562|L: 0.055,Acc 99.2,AUC 0.746,KS 0.391|L: 0.234,Acc 99.1,AUC 0.719,KS 0.362\n",
      " 28. L: 0.049,Acc 99.2,AUC 0.868,KS 0.561|L: 0.054,Acc 99.2,AUC 0.733,KS 0.332|L: 0.254,Acc 99.1,AUC 0.707,KS 0.321\n",
      " 29. L: 0.048,Acc 99.2,AUC 0.866,KS 0.563|L: 0.055,Acc 99.2,AUC 0.745,KS 0.378|L: 0.280,Acc 99.1,AUC 0.718,KS 0.355\n",
      " 30. L: 0.048,Acc 99.2,AUC 0.867,KS 0.555|L: 0.054,Acc 99.2,AUC 0.755,KS 0.388|L: 0.266,Acc 99.1,AUC 0.721,KS 0.371\n",
      " 31. L: 0.048,Acc 99.2,AUC 0.871,KS 0.562|L: 0.055,Acc 99.2,AUC 0.740,KS 0.376|L: 0.274,Acc 99.1,AUC 0.713,KS 0.378\n",
      " 32. L: 0.048,Acc 99.2,AUC 0.870,KS 0.565|L: 0.053,Acc 99.2,AUC 0.747,KS 0.362|L: 0.257,Acc 99.1,AUC 0.717,KS 0.366\n",
      " 33. L: 0.047,Acc 99.2,AUC 0.871,KS 0.568|L: 0.055,Acc 99.2,AUC 0.743,KS 0.352|L: 0.274,Acc 99.1,AUC 0.721,KS 0.353\n",
      " 34. L: 0.047,Acc 99.2,AUC 0.872,KS 0.573|L: 0.054,Acc 99.2,AUC 0.741,KS 0.341|L: 0.247,Acc 99.1,AUC 0.713,KS 0.349\n",
      " 35. L: 0.047,Acc 99.2,AUC 0.873,KS 0.579|L: 0.053,Acc 99.2,AUC 0.736,KS 0.334|L: 0.252,Acc 99.1,AUC 0.715,KS 0.377\n",
      " 36. L: 0.047,Acc 99.2,AUC 0.876,KS 0.578|L: 0.054,Acc 99.2,AUC 0.739,KS 0.361|L: 0.265,Acc 99.1,AUC 0.720,KS 0.364\n",
      " 37. L: 0.047,Acc 99.2,AUC 0.868,KS 0.576|L: 0.053,Acc 99.2,AUC 0.756,KS 0.377|L: 0.257,Acc 99.1,AUC 0.723,KS 0.349\n",
      " 38. L: 0.046,Acc 99.2,AUC 0.877,KS 0.582|L: 0.054,Acc 99.2,AUC 0.742,KS 0.325|L: 0.247,Acc 99.1,AUC 0.724,KS 0.359\n",
      " 39. L: 0.046,Acc 99.2,AUC 0.862,KS 0.556|L: 0.055,Acc 99.2,AUC 0.744,KS 0.338|L: 0.281,Acc 99.1,AUC 0.712,KS 0.360\n",
      " 40. L: 0.046,Acc 99.2,AUC 0.882,KS 0.585|L: 0.055,Acc 99.2,AUC 0.736,KS 0.350|L: 0.256,Acc 99.1,AUC 0.713,KS 0.342\n",
      " 41. L: 0.047,Acc 99.2,AUC 0.879,KS 0.580|L: 0.055,Acc 99.2,AUC 0.746,KS 0.343|L: 0.276,Acc 99.1,AUC 0.718,KS 0.342\n",
      " 42. L: 0.047,Acc 99.2,AUC 0.880,KS 0.584|L: 0.055,Acc 99.2,AUC 0.737,KS 0.344|L: 0.264,Acc 99.1,AUC 0.718,KS 0.352\n",
      " 43. L: 0.046,Acc 99.2,AUC 0.883,KS 0.584|L: 0.056,Acc 99.2,AUC 0.739,KS 0.353|L: 0.268,Acc 99.1,AUC 0.718,KS 0.360\n",
      " 44. L: 0.046,Acc 99.2,AUC 0.884,KS 0.591|L: 0.055,Acc 99.2,AUC 0.726,KS 0.338|L: 0.257,Acc 99.1,AUC 0.709,KS 0.328\n",
      " 45. L: 0.046,Acc 99.2,AUC 0.872,KS 0.564|L: 0.054,Acc 99.2,AUC 0.741,KS 0.353|L: 0.270,Acc 99.2,AUC 0.714,KS 0.365\n",
      " 46. L: 0.046,Acc 99.2,AUC 0.886,KS 0.594|L: 0.055,Acc 99.2,AUC 0.727,KS 0.355|L: 0.266,Acc 99.1,AUC 0.707,KS 0.338\n",
      " 47. L: 0.045,Acc 99.2,AUC 0.880,KS 0.591|L: 0.054,Acc 99.2,AUC 0.737,KS 0.342|L: 0.262,Acc 99.2,AUC 0.712,KS 0.354\n",
      " 48. L: 0.045,Acc 99.2,AUC 0.889,KS 0.596|L: 0.056,Acc 99.2,AUC 0.720,KS 0.321|L: 0.263,Acc 99.1,AUC 0.706,KS 0.302\n",
      " 49. L: 0.045,Acc 99.2,AUC 0.885,KS 0.600|L: 0.056,Acc 99.2,AUC 0.726,KS 0.326|L: 0.272,Acc 99.1,AUC 0.709,KS 0.338\n",
      " 50. L: 0.045,Acc 99.2,AUC 0.889,KS 0.593|L: 0.056,Acc 99.2,AUC 0.719,KS 0.315|L: 0.272,Acc 99.1,AUC 0.704,KS 0.323\n",
      "Valid AUC: 0.767, Valid KS: 0.439\n",
      "Test AUC: 0.734, Test KS: 0.364\n",
      "fold 3\n",
      "  1. L: 0.110,Acc 99.1,AUC 0.762,KS 0.383|L: 0.068,Acc 99.1,AUC 0.736,KS 0.364|L: 0.417,Acc 99.2,AUC 0.803,KS 0.453\n",
      "  2. L: 0.058,Acc 99.2,AUC 0.774,KS 0.405|L: 0.065,Acc 99.1,AUC 0.729,KS 0.320|L: 0.415,Acc 99.2,AUC 0.757,KS 0.444\n",
      "  3. L: 0.055,Acc 99.2,AUC 0.785,KS 0.432|L: 0.062,Acc 99.1,AUC 0.721,KS 0.326|L: 0.379,Acc 99.2,AUC 0.747,KS 0.407\n",
      "  4. L: 0.054,Acc 99.2,AUC 0.788,KS 0.425|L: 0.060,Acc 99.1,AUC 0.754,KS 0.396|L: 0.346,Acc 99.2,AUC 0.826,KS 0.462\n",
      "  5. L: 0.053,Acc 99.2,AUC 0.770,KS 0.396|L: 0.064,Acc 99.1,AUC 0.743,KS 0.365|L: 0.404,Acc 99.2,AUC 0.820,KS 0.448\n",
      "  6. L: 0.053,Acc 99.2,AUC 0.799,KS 0.452|L: 0.063,Acc 99.1,AUC 0.745,KS 0.369|L: 0.365,Acc 99.2,AUC 0.793,KS 0.475\n",
      "  7. L: 0.052,Acc 99.2,AUC 0.809,KS 0.464|L: 0.059,Acc 99.1,AUC 0.743,KS 0.380|L: 0.327,Acc 99.2,AUC 0.803,KS 0.459\n",
      "  8. L: 0.052,Acc 99.2,AUC 0.800,KS 0.438|L: 0.063,Acc 99.1,AUC 0.757,KS 0.384|L: 0.402,Acc 99.2,AUC 0.817,KS 0.475\n",
      "  9. L: 0.051,Acc 99.2,AUC 0.801,KS 0.454|L: 0.060,Acc 99.1,AUC 0.759,KS 0.386|L: 0.362,Acc 99.2,AUC 0.805,KS 0.468\n",
      " 10. L: 0.051,Acc 99.2,AUC 0.812,KS 0.466|L: 0.059,Acc 99.1,AUC 0.754,KS 0.420|L: 0.329,Acc 99.2,AUC 0.824,KS 0.497\n",
      " 11. L: 0.051,Acc 99.2,AUC 0.816,KS 0.465|L: 0.059,Acc 99.1,AUC 0.746,KS 0.413|L: 0.310,Acc 99.1,AUC 0.790,KS 0.437\n",
      " 12. L: 0.056,Acc 99.1,AUC 0.802,KS 0.454|L: 0.063,Acc 99.0,AUC 0.735,KS 0.352|L: 0.333,Acc 99.1,AUC 0.795,KS 0.464\n",
      " 13. L: 0.051,Acc 99.2,AUC 0.827,KS 0.496|L: 0.060,Acc 99.1,AUC 0.752,KS 0.394|L: 0.332,Acc 99.1,AUC 0.779,KS 0.450\n",
      " 14. L: 0.051,Acc 99.2,AUC 0.826,KS 0.499|L: 0.059,Acc 99.1,AUC 0.751,KS 0.390|L: 0.343,Acc 99.2,AUC 0.779,KS 0.443\n",
      " 15. L: 0.052,Acc 99.2,AUC 0.822,KS 0.496|L: 0.063,Acc 99.1,AUC 0.746,KS 0.384|L: 0.389,Acc 99.2,AUC 0.809,KS 0.490\n",
      " 16. L: 0.050,Acc 99.2,AUC 0.825,KS 0.487|L: 0.059,Acc 99.1,AUC 0.754,KS 0.396|L: 0.343,Acc 99.1,AUC 0.802,KS 0.481\n",
      " 17. L: 0.050,Acc 99.2,AUC 0.827,KS 0.494|L: 0.059,Acc 99.1,AUC 0.754,KS 0.393|L: 0.343,Acc 99.2,AUC 0.813,KS 0.503\n",
      " 18. L: 0.050,Acc 99.2,AUC 0.833,KS 0.506|L: 0.059,Acc 99.0,AUC 0.756,KS 0.416|L: 0.317,Acc 99.2,AUC 0.809,KS 0.462\n",
      " 19. L: 0.050,Acc 99.2,AUC 0.834,KS 0.506|L: 0.060,Acc 99.1,AUC 0.756,KS 0.376|L: 0.354,Acc 99.2,AUC 0.794,KS 0.464\n",
      " 20. L: 0.050,Acc 99.2,AUC 0.835,KS 0.509|L: 0.061,Acc 99.1,AUC 0.750,KS 0.385|L: 0.353,Acc 99.1,AUC 0.805,KS 0.490\n",
      " 21. L: 0.050,Acc 99.2,AUC 0.821,KS 0.490|L: 0.060,Acc 99.1,AUC 0.750,KS 0.414|L: 0.352,Acc 99.2,AUC 0.807,KS 0.489\n",
      " 22. L: 0.049,Acc 99.2,AUC 0.842,KS 0.510|L: 0.061,Acc 99.1,AUC 0.747,KS 0.374|L: 0.371,Acc 99.2,AUC 0.777,KS 0.453\n",
      " 23. L: 0.050,Acc 99.2,AUC 0.845,KS 0.524|L: 0.060,Acc 99.1,AUC 0.753,KS 0.382|L: 0.333,Acc 99.1,AUC 0.785,KS 0.458\n",
      " 24. L: 0.050,Acc 99.2,AUC 0.848,KS 0.530|L: 0.060,Acc 99.1,AUC 0.754,KS 0.420|L: 0.363,Acc 99.1,AUC 0.779,KS 0.480\n",
      " 25. L: 0.050,Acc 99.2,AUC 0.850,KS 0.535|L: 0.060,Acc 99.1,AUC 0.757,KS 0.405|L: 0.342,Acc 99.1,AUC 0.776,KS 0.447\n",
      " 26. L: 0.049,Acc 99.2,AUC 0.849,KS 0.529|L: 0.059,Acc 99.1,AUC 0.756,KS 0.415|L: 0.351,Acc 99.1,AUC 0.788,KS 0.465\n",
      " 27. L: 0.049,Acc 99.2,AUC 0.856,KS 0.537|L: 0.061,Acc 99.1,AUC 0.755,KS 0.415|L: 0.370,Acc 99.1,AUC 0.772,KS 0.467\n",
      " 28. L: 0.049,Acc 99.2,AUC 0.845,KS 0.524|L: 0.061,Acc 99.1,AUC 0.752,KS 0.393|L: 0.375,Acc 99.1,AUC 0.786,KS 0.449\n",
      " 29. L: 0.048,Acc 99.2,AUC 0.854,KS 0.543|L: 0.060,Acc 99.1,AUC 0.752,KS 0.393|L: 0.366,Acc 99.1,AUC 0.776,KS 0.464\n",
      " 30. L: 0.049,Acc 99.2,AUC 0.857,KS 0.546|L: 0.061,Acc 99.1,AUC 0.746,KS 0.397|L: 0.368,Acc 99.1,AUC 0.763,KS 0.446\n",
      " 31. L: 0.048,Acc 99.2,AUC 0.854,KS 0.542|L: 0.060,Acc 99.1,AUC 0.747,KS 0.386|L: 0.360,Acc 99.1,AUC 0.773,KS 0.437\n",
      " 32. L: 0.048,Acc 99.2,AUC 0.852,KS 0.534|L: 0.063,Acc 99.1,AUC 0.751,KS 0.379|L: 0.400,Acc 99.1,AUC 0.769,KS 0.432\n",
      " 33. L: 0.048,Acc 99.2,AUC 0.862,KS 0.562|L: 0.060,Acc 99.1,AUC 0.747,KS 0.410|L: 0.340,Acc 99.1,AUC 0.779,KS 0.437\n",
      " 34. L: 0.048,Acc 99.2,AUC 0.865,KS 0.564|L: 0.061,Acc 99.1,AUC 0.743,KS 0.395|L: 0.360,Acc 99.1,AUC 0.764,KS 0.466\n",
      " 35. L: 0.048,Acc 99.2,AUC 0.867,KS 0.562|L: 0.061,Acc 99.1,AUC 0.741,KS 0.393|L: 0.395,Acc 99.1,AUC 0.770,KS 0.483\n",
      " 36. L: 0.047,Acc 99.2,AUC 0.872,KS 0.573|L: 0.061,Acc 99.1,AUC 0.738,KS 0.383|L: 0.387,Acc 99.1,AUC 0.764,KS 0.440\n",
      " 37. L: 0.048,Acc 99.2,AUC 0.862,KS 0.561|L: 0.060,Acc 99.1,AUC 0.752,KS 0.411|L: 0.378,Acc 99.1,AUC 0.780,KS 0.449\n",
      " 38. L: 0.047,Acc 99.2,AUC 0.863,KS 0.561|L: 0.061,Acc 99.1,AUC 0.736,KS 0.377|L: 0.392,Acc 99.1,AUC 0.754,KS 0.449\n",
      " 39. L: 0.047,Acc 99.2,AUC 0.865,KS 0.567|L: 0.060,Acc 99.1,AUC 0.749,KS 0.383|L: 0.376,Acc 99.1,AUC 0.770,KS 0.454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40. L: 0.046,Acc 99.2,AUC 0.877,KS 0.583|L: 0.061,Acc 99.0,AUC 0.744,KS 0.372|L: 0.381,Acc 99.1,AUC 0.765,KS 0.440\n",
      " 41. L: 0.046,Acc 99.2,AUC 0.873,KS 0.569|L: 0.061,Acc 99.1,AUC 0.742,KS 0.384|L: 0.377,Acc 99.1,AUC 0.770,KS 0.469\n",
      " 42. L: 0.047,Acc 99.2,AUC 0.857,KS 0.546|L: 0.060,Acc 99.1,AUC 0.742,KS 0.371|L: 0.368,Acc 99.1,AUC 0.778,KS 0.477\n",
      " 43. L: 0.047,Acc 99.2,AUC 0.872,KS 0.569|L: 0.060,Acc 99.1,AUC 0.744,KS 0.397|L: 0.374,Acc 99.1,AUC 0.766,KS 0.480\n",
      " 44. L: 0.046,Acc 99.2,AUC 0.876,KS 0.577|L: 0.061,Acc 99.0,AUC 0.745,KS 0.397|L: 0.380,Acc 99.1,AUC 0.769,KS 0.483\n",
      " 45. L: 0.047,Acc 99.2,AUC 0.877,KS 0.575|L: 0.061,Acc 99.1,AUC 0.743,KS 0.385|L: 0.387,Acc 99.1,AUC 0.774,KS 0.487\n",
      " 46. L: 0.046,Acc 99.2,AUC 0.878,KS 0.584|L: 0.061,Acc 99.1,AUC 0.743,KS 0.401|L: 0.385,Acc 99.1,AUC 0.767,KS 0.480\n",
      " 47. L: 0.046,Acc 99.2,AUC 0.876,KS 0.581|L: 0.061,Acc 99.1,AUC 0.743,KS 0.396|L: 0.387,Acc 99.1,AUC 0.763,KS 0.482\n",
      " 48. L: 0.046,Acc 99.2,AUC 0.835,KS 0.495|L: 0.061,Acc 99.1,AUC 0.736,KS 0.366|L: 0.382,Acc 99.1,AUC 0.753,KS 0.423\n",
      " 49. L: 0.046,Acc 99.2,AUC 0.881,KS 0.589|L: 0.063,Acc 99.0,AUC 0.738,KS 0.374|L: 0.410,Acc 99.1,AUC 0.759,KS 0.467\n",
      " 50. L: 0.046,Acc 99.2,AUC 0.878,KS 0.583|L: 0.061,Acc 99.1,AUC 0.742,KS 0.392|L: 0.388,Acc 99.1,AUC 0.762,KS 0.478\n",
      "Valid AUC: 0.754, Valid KS: 0.420\n",
      "Test AUC: 0.824, Test KS: 0.497\n",
      "fold 4\n",
      "  1. L: 0.111,Acc 99.1,AUC 0.738,KS 0.358|L: 0.082,Acc 98.8,AUC 0.662,KS 0.241|L: 0.393,Acc 99.0,AUC 0.712,KS 0.329\n",
      "  2. L: 0.063,Acc 99.1,AUC 0.779,KS 0.431|L: 0.070,Acc 98.9,AUC 0.718,KS 0.319|L: 0.351,Acc 99.2,AUC 0.724,KS 0.325\n",
      "  3. L: 0.054,Acc 99.2,AUC 0.796,KS 0.463|L: 0.072,Acc 98.9,AUC 0.722,KS 0.362|L: 0.355,Acc 99.2,AUC 0.741,KS 0.371\n",
      "  4. L: 0.052,Acc 99.2,AUC 0.801,KS 0.455|L: 0.069,Acc 98.9,AUC 0.725,KS 0.334|L: 0.337,Acc 99.2,AUC 0.753,KS 0.382\n",
      "  5. L: 0.052,Acc 99.2,AUC 0.808,KS 0.483|L: 0.069,Acc 98.9,AUC 0.722,KS 0.350|L: 0.328,Acc 99.2,AUC 0.754,KS 0.371\n",
      "  6. L: 0.052,Acc 99.2,AUC 0.806,KS 0.465|L: 0.070,Acc 98.9,AUC 0.719,KS 0.346|L: 0.339,Acc 99.2,AUC 0.734,KS 0.351\n",
      "  7. L: 0.052,Acc 99.2,AUC 0.810,KS 0.479|L: 0.074,Acc 98.9,AUC 0.719,KS 0.319|L: 0.398,Acc 99.2,AUC 0.739,KS 0.358\n",
      "  8. L: 0.051,Acc 99.2,AUC 0.821,KS 0.507|L: 0.068,Acc 98.9,AUC 0.741,KS 0.369|L: 0.311,Acc 99.1,AUC 0.741,KS 0.345\n",
      "  9. L: 0.051,Acc 99.2,AUC 0.811,KS 0.480|L: 0.069,Acc 98.9,AUC 0.741,KS 0.389|L: 0.315,Acc 99.2,AUC 0.764,KS 0.407\n",
      " 10. L: 0.051,Acc 99.2,AUC 0.816,KS 0.477|L: 0.069,Acc 98.9,AUC 0.737,KS 0.354|L: 0.300,Acc 99.2,AUC 0.754,KS 0.397\n",
      " 11. L: 0.050,Acc 99.2,AUC 0.821,KS 0.489|L: 0.069,Acc 98.9,AUC 0.730,KS 0.347|L: 0.334,Acc 99.2,AUC 0.752,KS 0.400\n",
      " 12. L: 0.050,Acc 99.2,AUC 0.822,KS 0.495|L: 0.070,Acc 98.9,AUC 0.724,KS 0.328|L: 0.336,Acc 99.2,AUC 0.734,KS 0.345\n",
      " 13. L: 0.049,Acc 99.2,AUC 0.823,KS 0.492|L: 0.068,Acc 98.9,AUC 0.726,KS 0.326|L: 0.328,Acc 99.2,AUC 0.727,KS 0.343\n",
      " 14. L: 0.050,Acc 99.2,AUC 0.778,KS 0.444|L: 0.074,Acc 98.9,AUC 0.692,KS 0.301|L: 0.382,Acc 99.2,AUC 0.691,KS 0.313\n",
      " 15. L: 0.053,Acc 99.2,AUC 0.824,KS 0.505|L: 0.068,Acc 98.9,AUC 0.735,KS 0.347|L: 0.324,Acc 99.2,AUC 0.758,KS 0.373\n",
      " 16. L: 0.054,Acc 99.2,AUC 0.825,KS 0.511|L: 0.069,Acc 98.9,AUC 0.734,KS 0.356|L: 0.349,Acc 99.2,AUC 0.740,KS 0.346\n",
      " 17. L: 0.050,Acc 99.2,AUC 0.833,KS 0.527|L: 0.068,Acc 98.9,AUC 0.735,KS 0.328|L: 0.331,Acc 99.2,AUC 0.743,KS 0.348\n",
      " 18. L: 0.049,Acc 99.2,AUC 0.841,KS 0.527|L: 0.071,Acc 98.9,AUC 0.728,KS 0.333|L: 0.342,Acc 99.2,AUC 0.757,KS 0.375\n",
      " 19. L: 0.049,Acc 99.2,AUC 0.844,KS 0.533|L: 0.069,Acc 98.9,AUC 0.736,KS 0.345|L: 0.337,Acc 99.2,AUC 0.741,KS 0.347\n",
      " 20. L: 0.052,Acc 99.2,AUC 0.846,KS 0.536|L: 0.071,Acc 98.9,AUC 0.737,KS 0.363|L: 0.354,Acc 99.2,AUC 0.748,KS 0.348\n",
      " 21. L: 0.049,Acc 99.2,AUC 0.844,KS 0.526|L: 0.072,Acc 98.9,AUC 0.732,KS 0.337|L: 0.355,Acc 99.2,AUC 0.757,KS 0.360\n",
      " 22. L: 0.048,Acc 99.2,AUC 0.845,KS 0.540|L: 0.068,Acc 98.9,AUC 0.735,KS 0.355|L: 0.319,Acc 99.2,AUC 0.755,KS 0.407\n",
      " 23. L: 0.047,Acc 99.2,AUC 0.839,KS 0.520|L: 0.074,Acc 98.9,AUC 0.731,KS 0.334|L: 0.360,Acc 99.2,AUC 0.753,KS 0.387\n",
      " 24. L: 0.048,Acc 99.2,AUC 0.857,KS 0.554|L: 0.068,Acc 98.9,AUC 0.741,KS 0.370|L: 0.318,Acc 99.2,AUC 0.752,KS 0.388\n",
      " 25. L: 0.047,Acc 99.2,AUC 0.855,KS 0.557|L: 0.071,Acc 98.9,AUC 0.730,KS 0.356|L: 0.353,Acc 99.2,AUC 0.743,KS 0.343\n",
      " 26. L: 0.047,Acc 99.2,AUC 0.858,KS 0.551|L: 0.071,Acc 98.9,AUC 0.730,KS 0.331|L: 0.340,Acc 99.2,AUC 0.746,KS 0.373\n",
      " 27. L: 0.047,Acc 99.2,AUC 0.855,KS 0.550|L: 0.070,Acc 98.9,AUC 0.730,KS 0.326|L: 0.340,Acc 99.2,AUC 0.733,KS 0.327\n",
      " 28. L: 0.048,Acc 99.2,AUC 0.863,KS 0.564|L: 0.070,Acc 98.9,AUC 0.731,KS 0.357|L: 0.333,Acc 99.2,AUC 0.745,KS 0.359\n",
      " 29. L: 0.047,Acc 99.2,AUC 0.746,KS 0.349|L: 0.076,Acc 98.9,AUC 0.658,KS 0.256|L: 0.427,Acc 99.2,AUC 0.717,KS 0.311\n",
      " 30. L: 0.047,Acc 99.2,AUC 0.869,KS 0.569|L: 0.071,Acc 98.9,AUC 0.723,KS 0.338|L: 0.347,Acc 99.2,AUC 0.755,KS 0.403\n",
      " 31. L: 0.046,Acc 99.2,AUC 0.852,KS 0.545|L: 0.073,Acc 98.9,AUC 0.728,KS 0.327|L: 0.377,Acc 99.2,AUC 0.752,KS 0.363\n",
      " 32. L: 0.046,Acc 99.2,AUC 0.868,KS 0.573|L: 0.070,Acc 98.9,AUC 0.734,KS 0.351|L: 0.333,Acc 99.2,AUC 0.746,KS 0.373\n",
      " 33. L: 0.046,Acc 99.2,AUC 0.875,KS 0.592|L: 0.070,Acc 98.9,AUC 0.726,KS 0.336|L: 0.326,Acc 99.2,AUC 0.742,KS 0.358\n",
      " 34. L: 0.047,Acc 99.2,AUC 0.872,KS 0.582|L: 0.071,Acc 98.9,AUC 0.726,KS 0.323|L: 0.343,Acc 99.2,AUC 0.747,KS 0.366\n",
      " 35. L: 0.047,Acc 99.2,AUC 0.876,KS 0.591|L: 0.071,Acc 98.9,AUC 0.724,KS 0.322|L: 0.353,Acc 99.2,AUC 0.749,KS 0.378\n",
      " 36. L: 0.047,Acc 99.2,AUC 0.874,KS 0.585|L: 0.071,Acc 98.9,AUC 0.734,KS 0.360|L: 0.343,Acc 99.2,AUC 0.756,KS 0.370\n",
      " 37. L: 0.046,Acc 99.2,AUC 0.876,KS 0.584|L: 0.073,Acc 98.9,AUC 0.731,KS 0.339|L: 0.361,Acc 99.2,AUC 0.752,KS 0.353\n",
      " 38. L: 0.046,Acc 99.2,AUC 0.877,KS 0.591|L: 0.071,Acc 98.9,AUC 0.735,KS 0.343|L: 0.336,Acc 99.2,AUC 0.753,KS 0.355\n",
      " 39. L: 0.045,Acc 99.2,AUC 0.878,KS 0.590|L: 0.073,Acc 98.9,AUC 0.734,KS 0.352|L: 0.360,Acc 99.2,AUC 0.759,KS 0.385\n",
      " 40. L: 0.045,Acc 99.2,AUC 0.879,KS 0.592|L: 0.072,Acc 98.9,AUC 0.734,KS 0.347|L: 0.337,Acc 99.1,AUC 0.763,KS 0.391\n",
      " 41. L: 0.045,Acc 99.2,AUC 0.886,KS 0.605|L: 0.073,Acc 98.9,AUC 0.722,KS 0.334|L: 0.362,Acc 99.2,AUC 0.744,KS 0.347\n",
      " 42. L: 0.044,Acc 99.2,AUC 0.885,KS 0.605|L: 0.072,Acc 98.9,AUC 0.724,KS 0.325|L: 0.349,Acc 99.2,AUC 0.744,KS 0.357\n",
      " 43. L: 0.045,Acc 99.2,AUC 0.885,KS 0.609|L: 0.072,Acc 98.8,AUC 0.726,KS 0.348|L: 0.324,Acc 99.1,AUC 0.754,KS 0.386\n",
      " 44. L: 0.046,Acc 99.2,AUC 0.884,KS 0.607|L: 0.072,Acc 98.9,AUC 0.729,KS 0.356|L: 0.341,Acc 99.1,AUC 0.756,KS 0.380\n",
      " 45. L: 0.045,Acc 99.2,AUC 0.885,KS 0.611|L: 0.071,Acc 98.9,AUC 0.725,KS 0.336|L: 0.336,Acc 99.1,AUC 0.758,KS 0.371\n",
      " 46. L: 0.044,Acc 99.2,AUC 0.883,KS 0.603|L: 0.070,Acc 98.9,AUC 0.724,KS 0.322|L: 0.336,Acc 99.1,AUC 0.753,KS 0.376\n",
      " 47. L: 0.044,Acc 99.2,AUC 0.889,KS 0.612|L: 0.073,Acc 98.9,AUC 0.725,KS 0.340|L: 0.335,Acc 99.1,AUC 0.754,KS 0.365\n",
      " 48. L: 0.044,Acc 99.2,AUC 0.889,KS 0.616|L: 0.072,Acc 98.9,AUC 0.723,KS 0.349|L: 0.332,Acc 99.1,AUC 0.753,KS 0.384\n",
      " 49. L: 0.044,Acc 99.2,AUC 0.886,KS 0.616|L: 0.071,Acc 98.9,AUC 0.724,KS 0.331|L: 0.338,Acc 99.1,AUC 0.755,KS 0.377\n",
      " 50. L: 0.044,Acc 99.2,AUC 0.886,KS 0.617|L: 0.072,Acc 98.9,AUC 0.722,KS 0.325|L: 0.349,Acc 99.1,AUC 0.750,KS 0.360\n",
      "Valid AUC: 0.741, Valid KS: 0.389\n",
      "Test AUC: 0.764, Test KS: 0.407\n",
      "fold 5\n",
      "  1. L: 0.145,Acc 99.0,AUC 0.694,KS 0.295|L: 0.050,Acc 99.3,AUC 0.687,KS 0.275|L: 0.475,Acc 99.1,AUC 0.596,KS 0.183\n",
      "  2. L: 0.060,Acc 99.1,AUC 0.700,KS 0.288|L: 0.046,Acc 99.3,AUC 0.697,KS 0.273|L: 0.475,Acc 99.2,AUC 0.623,KS 0.238\n",
      "  3. L: 0.057,Acc 99.1,AUC 0.770,KS 0.394|L: 0.043,Acc 99.3,AUC 0.756,KS 0.372|L: 0.364,Acc 99.2,AUC 0.756,KS 0.421\n",
      "  4. L: 0.056,Acc 99.1,AUC 0.782,KS 0.419|L: 0.043,Acc 99.3,AUC 0.786,KS 0.460|L: 0.379,Acc 99.2,AUC 0.755,KS 0.402\n",
      "  5. L: 0.056,Acc 99.1,AUC 0.791,KS 0.425|L: 0.042,Acc 99.3,AUC 0.789,KS 0.447|L: 0.383,Acc 99.2,AUC 0.762,KS 0.437\n",
      "  6. L: 0.056,Acc 99.1,AUC 0.805,KS 0.453|L: 0.042,Acc 99.3,AUC 0.809,KS 0.501|L: 0.387,Acc 99.2,AUC 0.744,KS 0.441\n",
      "  7. L: 0.055,Acc 99.1,AUC 0.811,KS 0.474|L: 0.065,Acc 99.3,AUC 0.800,KS 0.484|L: 0.264,Acc 99.2,AUC 0.752,KS 0.465\n",
      "  8. L: 0.057,Acc 99.1,AUC 0.807,KS 0.470|L: 0.041,Acc 99.3,AUC 0.803,KS 0.487|L: 0.376,Acc 99.2,AUC 0.767,KS 0.476\n",
      "  9. L: 0.055,Acc 99.1,AUC 0.810,KS 0.474|L: 0.041,Acc 99.3,AUC 0.811,KS 0.543|L: 0.344,Acc 99.2,AUC 0.756,KS 0.419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10. L: 0.056,Acc 99.1,AUC 0.803,KS 0.453|L: 0.042,Acc 99.3,AUC 0.802,KS 0.509|L: 0.415,Acc 99.2,AUC 0.732,KS 0.400\n",
      " 11. L: 0.053,Acc 99.1,AUC 0.814,KS 0.466|L: 0.041,Acc 99.3,AUC 0.807,KS 0.488|L: 0.352,Acc 99.2,AUC 0.726,KS 0.434\n",
      " 12. L: 0.053,Acc 99.1,AUC 0.815,KS 0.490|L: 0.041,Acc 99.3,AUC 0.809,KS 0.471|L: 0.371,Acc 99.2,AUC 0.736,KS 0.422\n",
      " 13. L: 0.054,Acc 99.1,AUC 0.815,KS 0.465|L: 0.042,Acc 99.3,AUC 0.801,KS 0.517|L: 0.406,Acc 99.2,AUC 0.733,KS 0.405\n",
      " 14. L: 0.052,Acc 99.1,AUC 0.815,KS 0.476|L: 0.042,Acc 99.3,AUC 0.811,KS 0.465|L: 0.409,Acc 99.2,AUC 0.762,KS 0.437\n",
      " 15. L: 0.053,Acc 99.1,AUC 0.826,KS 0.495|L: 0.041,Acc 99.3,AUC 0.823,KS 0.510|L: 0.344,Acc 99.2,AUC 0.749,KS 0.437\n",
      " 16. L: 0.053,Acc 99.1,AUC 0.832,KS 0.504|L: 0.041,Acc 99.3,AUC 0.804,KS 0.455|L: 0.357,Acc 99.2,AUC 0.728,KS 0.417\n",
      " 17. L: 0.054,Acc 99.1,AUC 0.825,KS 0.489|L: 0.041,Acc 99.3,AUC 0.801,KS 0.445|L: 0.393,Acc 99.2,AUC 0.738,KS 0.400\n",
      " 18. L: 0.052,Acc 99.1,AUC 0.815,KS 0.465|L: 0.042,Acc 99.3,AUC 0.777,KS 0.413|L: 0.384,Acc 99.2,AUC 0.728,KS 0.401\n",
      " 19. L: 0.052,Acc 99.1,AUC 0.832,KS 0.509|L: 0.041,Acc 99.3,AUC 0.806,KS 0.497|L: 0.348,Acc 99.2,AUC 0.756,KS 0.465\n",
      " 20. L: 0.052,Acc 99.1,AUC 0.835,KS 0.512|L: 0.041,Acc 99.3,AUC 0.814,KS 0.476|L: 0.378,Acc 99.2,AUC 0.738,KS 0.430\n",
      " 21. L: 0.051,Acc 99.1,AUC 0.837,KS 0.501|L: 0.041,Acc 99.3,AUC 0.811,KS 0.489|L: 0.363,Acc 99.2,AUC 0.733,KS 0.452\n",
      " 22. L: 0.051,Acc 99.1,AUC 0.839,KS 0.515|L: 0.041,Acc 99.3,AUC 0.813,KS 0.506|L: 0.397,Acc 99.2,AUC 0.744,KS 0.425\n",
      " 23. L: 0.051,Acc 99.1,AUC 0.846,KS 0.531|L: 0.040,Acc 99.3,AUC 0.818,KS 0.489|L: 0.370,Acc 99.2,AUC 0.723,KS 0.383\n",
      " 24. L: 0.051,Acc 99.1,AUC 0.851,KS 0.550|L: 0.041,Acc 99.3,AUC 0.804,KS 0.438|L: 0.365,Acc 99.2,AUC 0.722,KS 0.421\n",
      " 25. L: 0.051,Acc 99.1,AUC 0.839,KS 0.516|L: 0.042,Acc 99.3,AUC 0.808,KS 0.477|L: 0.347,Acc 99.2,AUC 0.726,KS 0.410\n",
      " 26. L: 0.051,Acc 99.1,AUC 0.850,KS 0.534|L: 0.041,Acc 99.3,AUC 0.806,KS 0.471|L: 0.362,Acc 99.2,AUC 0.732,KS 0.400\n",
      " 27. L: 0.050,Acc 99.1,AUC 0.851,KS 0.541|L: 0.041,Acc 99.3,AUC 0.812,KS 0.494|L: 0.364,Acc 99.2,AUC 0.741,KS 0.436\n",
      " 28. L: 0.049,Acc 99.1,AUC 0.858,KS 0.548|L: 0.041,Acc 99.3,AUC 0.803,KS 0.486|L: 0.358,Acc 99.2,AUC 0.732,KS 0.448\n",
      " 29. L: 0.050,Acc 99.1,AUC 0.857,KS 0.545|L: 0.041,Acc 99.3,AUC 0.811,KS 0.470|L: 0.401,Acc 99.2,AUC 0.716,KS 0.379\n",
      " 30. L: 0.050,Acc 99.1,AUC 0.857,KS 0.551|L: 0.041,Acc 99.3,AUC 0.804,KS 0.454|L: 0.385,Acc 99.2,AUC 0.727,KS 0.396\n",
      " 31. L: 0.050,Acc 99.1,AUC 0.860,KS 0.561|L: 0.041,Acc 99.3,AUC 0.803,KS 0.448|L: 0.377,Acc 99.2,AUC 0.724,KS 0.377\n",
      " 32. L: 0.049,Acc 99.1,AUC 0.850,KS 0.536|L: 0.041,Acc 99.3,AUC 0.796,KS 0.438|L: 0.386,Acc 99.2,AUC 0.739,KS 0.474\n",
      " 33. L: 0.049,Acc 99.1,AUC 0.862,KS 0.570|L: 0.041,Acc 99.3,AUC 0.806,KS 0.502|L: 0.381,Acc 99.2,AUC 0.728,KS 0.406\n",
      " 34. L: 0.049,Acc 99.1,AUC 0.859,KS 0.556|L: 0.041,Acc 99.3,AUC 0.798,KS 0.446|L: 0.397,Acc 99.2,AUC 0.729,KS 0.404\n",
      " 35. L: 0.049,Acc 99.1,AUC 0.854,KS 0.552|L: 0.041,Acc 99.3,AUC 0.796,KS 0.427|L: 0.397,Acc 99.2,AUC 0.724,KS 0.442\n",
      " 36. L: 0.050,Acc 99.1,AUC 0.848,KS 0.537|L: 0.042,Acc 99.3,AUC 0.793,KS 0.438|L: 0.379,Acc 99.2,AUC 0.721,KS 0.402\n",
      " 37. L: 0.049,Acc 99.1,AUC 0.867,KS 0.570|L: 0.042,Acc 99.3,AUC 0.800,KS 0.450|L: 0.391,Acc 99.2,AUC 0.730,KS 0.403\n",
      " 38. L: 0.049,Acc 99.1,AUC 0.867,KS 0.570|L: 0.042,Acc 99.3,AUC 0.797,KS 0.444|L: 0.387,Acc 99.2,AUC 0.726,KS 0.422\n",
      " 39. L: 0.049,Acc 99.1,AUC 0.871,KS 0.580|L: 0.041,Acc 99.3,AUC 0.798,KS 0.437|L: 0.427,Acc 99.2,AUC 0.704,KS 0.364\n",
      " 40. L: 0.048,Acc 99.1,AUC 0.868,KS 0.575|L: 0.042,Acc 99.3,AUC 0.793,KS 0.431|L: 0.386,Acc 99.2,AUC 0.716,KS 0.399\n",
      " 41. L: 0.048,Acc 99.1,AUC 0.873,KS 0.582|L: 0.042,Acc 99.3,AUC 0.795,KS 0.436|L: 0.405,Acc 99.2,AUC 0.715,KS 0.376\n",
      " 42. L: 0.049,Acc 99.1,AUC 0.850,KS 0.535|L: 0.042,Acc 99.3,AUC 0.783,KS 0.399|L: 0.396,Acc 99.2,AUC 0.717,KS 0.399\n",
      " 43. L: 0.047,Acc 99.1,AUC 0.864,KS 0.566|L: 0.042,Acc 99.3,AUC 0.789,KS 0.417|L: 0.376,Acc 99.2,AUC 0.723,KS 0.409\n",
      " 44. L: 0.048,Acc 99.1,AUC 0.871,KS 0.576|L: 0.041,Acc 99.3,AUC 0.793,KS 0.450|L: 0.397,Acc 99.2,AUC 0.726,KS 0.438\n",
      " 45. L: 0.048,Acc 99.2,AUC 0.858,KS 0.562|L: 0.042,Acc 99.3,AUC 0.786,KS 0.419|L: 0.374,Acc 99.2,AUC 0.719,KS 0.395\n",
      " 46. L: 0.048,Acc 99.1,AUC 0.875,KS 0.585|L: 0.042,Acc 99.3,AUC 0.794,KS 0.421|L: 0.426,Acc 99.2,AUC 0.714,KS 0.374\n",
      " 47. L: 0.048,Acc 99.1,AUC 0.876,KS 0.584|L: 0.041,Acc 99.3,AUC 0.798,KS 0.425|L: 0.392,Acc 99.2,AUC 0.717,KS 0.402\n",
      " 48. L: 0.047,Acc 99.1,AUC 0.877,KS 0.595|L: 0.042,Acc 99.3,AUC 0.795,KS 0.427|L: 0.401,Acc 99.2,AUC 0.710,KS 0.359\n",
      " 49. L: 0.048,Acc 99.1,AUC 0.877,KS 0.597|L: 0.042,Acc 99.3,AUC 0.795,KS 0.426|L: 0.415,Acc 99.2,AUC 0.709,KS 0.363\n",
      " 50. L: 0.047,Acc 99.2,AUC 0.878,KS 0.595|L: 0.042,Acc 99.3,AUC 0.793,KS 0.430|L: 0.424,Acc 99.2,AUC 0.707,KS 0.356\n",
      "Valid AUC: 0.811, Valid KS: 0.543\n",
      "Test AUC: 0.756, Test KS: 0.419\n",
      "fold 6\n",
      "  1. L: 0.101,Acc 99.0,AUC 0.747,KS 0.382|L: 0.054,Acc 99.2,AUC 0.714,KS 0.361|L: 0.268,Acc 99.2,AUC 0.747,KS 0.377\n",
      "  2. L: 0.058,Acc 99.1,AUC 0.762,KS 0.397|L: 0.060,Acc 99.2,AUC 0.743,KS 0.378|L: 0.380,Acc 99.2,AUC 0.792,KS 0.449\n",
      "  3. L: 0.056,Acc 99.1,AUC 0.780,KS 0.416|L: 0.051,Acc 99.2,AUC 0.745,KS 0.416|L: 0.276,Acc 99.2,AUC 0.787,KS 0.412\n",
      "  4. L: 0.056,Acc 99.2,AUC 0.794,KS 0.438|L: 0.051,Acc 99.2,AUC 0.757,KS 0.463|L: 0.279,Acc 99.2,AUC 0.797,KS 0.463\n",
      "  5. L: 0.055,Acc 99.2,AUC 0.801,KS 0.462|L: 0.050,Acc 99.2,AUC 0.768,KS 0.452|L: 0.259,Acc 99.2,AUC 0.815,KS 0.511\n",
      "  6. L: 0.054,Acc 99.1,AUC 0.801,KS 0.470|L: 0.051,Acc 99.2,AUC 0.756,KS 0.444|L: 0.293,Acc 99.2,AUC 0.801,KS 0.470\n",
      "  7. L: 0.060,Acc 99.1,AUC 0.685,KS 0.340|L: 0.059,Acc 99.2,AUC 0.695,KS 0.353|L: 0.313,Acc 99.2,AUC 0.718,KS 0.406\n",
      "  8. L: 0.057,Acc 99.1,AUC 0.798,KS 0.453|L: 0.050,Acc 99.2,AUC 0.760,KS 0.419|L: 0.290,Acc 99.2,AUC 0.808,KS 0.482\n",
      "  9. L: 0.054,Acc 99.1,AUC 0.804,KS 0.465|L: 0.050,Acc 99.2,AUC 0.765,KS 0.428|L: 0.292,Acc 99.2,AUC 0.816,KS 0.469\n",
      " 10. L: 0.053,Acc 99.2,AUC 0.811,KS 0.479|L: 0.051,Acc 99.2,AUC 0.768,KS 0.433|L: 0.243,Acc 99.2,AUC 0.834,KS 0.531\n",
      " 11. L: 0.052,Acc 99.2,AUC 0.806,KS 0.473|L: 0.050,Acc 99.2,AUC 0.759,KS 0.439|L: 0.285,Acc 99.2,AUC 0.802,KS 0.449\n",
      " 12. L: 0.052,Acc 99.2,AUC 0.814,KS 0.487|L: 0.050,Acc 99.2,AUC 0.771,KS 0.460|L: 0.274,Acc 99.2,AUC 0.811,KS 0.503\n",
      " 13. L: 0.054,Acc 99.1,AUC 0.802,KS 0.462|L: 0.052,Acc 99.2,AUC 0.759,KS 0.453|L: 0.239,Acc 99.2,AUC 0.830,KS 0.531\n",
      " 14. L: 0.052,Acc 99.2,AUC 0.819,KS 0.484|L: 0.050,Acc 99.2,AUC 0.771,KS 0.493|L: 0.290,Acc 99.2,AUC 0.845,KS 0.571\n",
      " 15. L: 0.051,Acc 99.2,AUC 0.815,KS 0.475|L: 0.051,Acc 99.2,AUC 0.765,KS 0.450|L: 0.299,Acc 99.2,AUC 0.809,KS 0.488\n",
      " 16. L: 0.052,Acc 99.2,AUC 0.819,KS 0.480|L: 0.050,Acc 99.2,AUC 0.768,KS 0.469|L: 0.273,Acc 99.2,AUC 0.828,KS 0.525\n",
      " 17. L: 0.052,Acc 99.2,AUC 0.781,KS 0.416|L: 0.051,Acc 99.2,AUC 0.738,KS 0.375|L: 0.297,Acc 99.2,AUC 0.765,KS 0.383\n",
      " 18. L: 0.051,Acc 99.2,AUC 0.826,KS 0.502|L: 0.050,Acc 99.2,AUC 0.765,KS 0.441|L: 0.258,Acc 99.2,AUC 0.839,KS 0.544\n",
      " 19. L: 0.052,Acc 99.2,AUC 0.820,KS 0.489|L: 0.051,Acc 99.2,AUC 0.760,KS 0.421|L: 0.293,Acc 99.2,AUC 0.811,KS 0.483\n",
      " 20. L: 0.051,Acc 99.2,AUC 0.829,KS 0.500|L: 0.050,Acc 99.2,AUC 0.759,KS 0.427|L: 0.290,Acc 99.2,AUC 0.818,KS 0.503\n",
      " 21. L: 0.051,Acc 99.2,AUC 0.830,KS 0.503|L: 0.050,Acc 99.2,AUC 0.761,KS 0.430|L: 0.274,Acc 99.2,AUC 0.824,KS 0.522\n",
      " 22. L: 0.057,Acc 99.2,AUC 0.819,KS 0.487|L: 0.049,Acc 99.2,AUC 0.778,KS 0.465|L: 0.277,Acc 99.2,AUC 0.827,KS 0.520\n",
      " 23. L: 0.052,Acc 99.2,AUC 0.812,KS 0.479|L: 0.050,Acc 99.2,AUC 0.756,KS 0.425|L: 0.284,Acc 99.2,AUC 0.802,KS 0.464\n",
      " 24. L: 0.051,Acc 99.2,AUC 0.820,KS 0.501|L: 0.050,Acc 99.2,AUC 0.758,KS 0.422|L: 0.268,Acc 99.2,AUC 0.815,KS 0.501\n",
      " 25. L: 0.051,Acc 99.2,AUC 0.824,KS 0.500|L: 0.050,Acc 99.2,AUC 0.767,KS 0.455|L: 0.260,Acc 99.2,AUC 0.822,KS 0.520\n",
      " 26. L: 0.050,Acc 99.2,AUC 0.826,KS 0.515|L: 0.050,Acc 99.2,AUC 0.767,KS 0.446|L: 0.269,Acc 99.2,AUC 0.818,KS 0.489\n",
      " 27. L: 0.050,Acc 99.2,AUC 0.837,KS 0.527|L: 0.050,Acc 99.2,AUC 0.764,KS 0.417|L: 0.263,Acc 99.2,AUC 0.829,KS 0.507\n",
      " 28. L: 0.050,Acc 99.2,AUC 0.839,KS 0.521|L: 0.050,Acc 99.2,AUC 0.757,KS 0.421|L: 0.278,Acc 99.2,AUC 0.837,KS 0.536\n",
      " 29. L: 0.050,Acc 99.2,AUC 0.839,KS 0.522|L: 0.050,Acc 99.2,AUC 0.755,KS 0.415|L: 0.274,Acc 99.2,AUC 0.831,KS 0.519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30. L: 0.050,Acc 99.2,AUC 0.828,KS 0.506|L: 0.050,Acc 99.2,AUC 0.749,KS 0.385|L: 0.274,Acc 99.2,AUC 0.808,KS 0.483\n",
      " 31. L: 0.050,Acc 99.2,AUC 0.837,KS 0.519|L: 0.050,Acc 99.2,AUC 0.757,KS 0.421|L: 0.267,Acc 99.2,AUC 0.823,KS 0.527\n",
      " 32. L: 0.050,Acc 99.2,AUC 0.841,KS 0.535|L: 0.051,Acc 99.2,AUC 0.759,KS 0.410|L: 0.301,Acc 99.2,AUC 0.824,KS 0.499\n",
      " 33. L: 0.050,Acc 99.2,AUC 0.810,KS 0.474|L: 0.050,Acc 99.2,AUC 0.756,KS 0.421|L: 0.280,Acc 99.2,AUC 0.801,KS 0.453\n",
      " 34. L: 0.049,Acc 99.2,AUC 0.843,KS 0.535|L: 0.053,Acc 99.2,AUC 0.757,KS 0.419|L: 0.306,Acc 99.2,AUC 0.829,KS 0.492\n",
      " 35. L: 0.049,Acc 99.2,AUC 0.849,KS 0.543|L: 0.051,Acc 99.2,AUC 0.757,KS 0.421|L: 0.266,Acc 99.2,AUC 0.829,KS 0.528\n",
      " 36. L: 0.049,Acc 99.2,AUC 0.849,KS 0.538|L: 0.051,Acc 99.2,AUC 0.751,KS 0.402|L: 0.258,Acc 99.2,AUC 0.827,KS 0.520\n",
      " 37. L: 0.049,Acc 99.2,AUC 0.847,KS 0.530|L: 0.050,Acc 99.2,AUC 0.752,KS 0.404|L: 0.267,Acc 99.2,AUC 0.817,KS 0.509\n",
      " 38. L: 0.049,Acc 99.2,AUC 0.849,KS 0.545|L: 0.051,Acc 99.2,AUC 0.750,KS 0.414|L: 0.275,Acc 99.2,AUC 0.815,KS 0.498\n",
      " 39. L: 0.048,Acc 99.2,AUC 0.853,KS 0.542|L: 0.051,Acc 99.2,AUC 0.750,KS 0.419|L: 0.256,Acc 99.2,AUC 0.813,KS 0.489\n",
      " 40. L: 0.049,Acc 99.2,AUC 0.841,KS 0.522|L: 0.051,Acc 99.2,AUC 0.747,KS 0.402|L: 0.273,Acc 99.2,AUC 0.814,KS 0.486\n",
      " 41. L: 0.049,Acc 99.2,AUC 0.855,KS 0.543|L: 0.051,Acc 99.2,AUC 0.732,KS 0.388|L: 0.260,Acc 99.2,AUC 0.815,KS 0.514\n",
      " 42. L: 0.049,Acc 99.2,AUC 0.861,KS 0.549|L: 0.051,Acc 99.2,AUC 0.735,KS 0.397|L: 0.267,Acc 99.2,AUC 0.814,KS 0.501\n",
      " 43. L: 0.048,Acc 99.2,AUC 0.860,KS 0.554|L: 0.051,Acc 99.2,AUC 0.741,KS 0.390|L: 0.273,Acc 99.2,AUC 0.814,KS 0.519\n",
      " 44. L: 0.048,Acc 99.2,AUC 0.861,KS 0.557|L: 0.052,Acc 99.2,AUC 0.734,KS 0.386|L: 0.279,Acc 99.2,AUC 0.813,KS 0.515\n",
      " 45. L: 0.048,Acc 99.2,AUC 0.863,KS 0.557|L: 0.052,Acc 99.2,AUC 0.736,KS 0.395|L: 0.279,Acc 99.1,AUC 0.818,KS 0.504\n",
      " 46. L: 0.049,Acc 99.2,AUC 0.863,KS 0.558|L: 0.052,Acc 99.2,AUC 0.736,KS 0.385|L: 0.277,Acc 99.2,AUC 0.818,KS 0.511\n",
      " 47. L: 0.048,Acc 99.2,AUC 0.854,KS 0.545|L: 0.051,Acc 99.2,AUC 0.739,KS 0.380|L: 0.281,Acc 99.2,AUC 0.816,KS 0.478\n",
      " 48. L: 0.047,Acc 99.2,AUC 0.858,KS 0.551|L: 0.051,Acc 99.2,AUC 0.741,KS 0.388|L: 0.278,Acc 99.2,AUC 0.816,KS 0.496\n",
      " 49. L: 0.048,Acc 99.2,AUC 0.856,KS 0.547|L: 0.051,Acc 99.2,AUC 0.740,KS 0.375|L: 0.279,Acc 99.2,AUC 0.813,KS 0.483\n",
      " 50. L: 0.048,Acc 99.2,AUC 0.864,KS 0.561|L: 0.051,Acc 99.2,AUC 0.737,KS 0.398|L: 0.274,Acc 99.2,AUC 0.814,KS 0.494\n",
      "Valid AUC: 0.771, Valid KS: 0.493\n",
      "Test AUC: 0.845, Test KS: 0.571\n",
      "fold 7\n",
      "  1. L: 0.107,Acc 99.0,AUC 0.674,KS 0.312|L: 0.073,Acc 99.0,AUC 0.612,KS 0.247|L: 0.459,Acc 99.2,AUC 0.636,KS 0.268\n",
      "  2. L: 0.061,Acc 99.1,AUC 0.763,KS 0.398|L: 0.062,Acc 99.0,AUC 0.700,KS 0.327|L: 0.357,Acc 99.2,AUC 0.771,KS 0.455\n",
      "  3. L: 0.056,Acc 99.2,AUC 0.793,KS 0.446|L: 0.061,Acc 99.0,AUC 0.741,KS 0.406|L: 0.318,Acc 99.2,AUC 0.787,KS 0.475\n",
      "  4. L: 0.054,Acc 99.2,AUC 0.785,KS 0.411|L: 0.069,Acc 99.0,AUC 0.755,KS 0.378|L: 0.448,Acc 99.2,AUC 0.795,KS 0.426\n",
      "  5. L: 0.054,Acc 99.2,AUC 0.805,KS 0.459|L: 0.061,Acc 99.0,AUC 0.753,KS 0.438|L: 0.352,Acc 99.2,AUC 0.790,KS 0.434\n",
      "  6. L: 0.053,Acc 99.2,AUC 0.792,KS 0.422|L: 0.062,Acc 99.0,AUC 0.751,KS 0.432|L: 0.388,Acc 99.2,AUC 0.800,KS 0.430\n",
      "  7. L: 0.052,Acc 99.2,AUC 0.808,KS 0.468|L: 0.060,Acc 99.0,AUC 0.766,KS 0.450|L: 0.365,Acc 99.2,AUC 0.815,KS 0.458\n",
      "  8. L: 0.052,Acc 99.2,AUC 0.812,KS 0.478|L: 0.059,Acc 99.0,AUC 0.760,KS 0.442|L: 0.351,Acc 99.2,AUC 0.799,KS 0.464\n",
      "  9. L: 0.053,Acc 99.2,AUC 0.815,KS 0.474|L: 0.059,Acc 99.0,AUC 0.766,KS 0.431|L: 0.353,Acc 99.2,AUC 0.797,KS 0.468\n",
      " 10. L: 0.053,Acc 99.2,AUC 0.789,KS 0.425|L: 0.063,Acc 99.0,AUC 0.747,KS 0.424|L: 0.359,Acc 99.1,AUC 0.773,KS 0.425\n",
      " 11. L: 0.051,Acc 99.2,AUC 0.819,KS 0.484|L: 0.059,Acc 99.0,AUC 0.774,KS 0.444|L: 0.347,Acc 99.2,AUC 0.823,KS 0.472\n",
      " 12. L: 0.051,Acc 99.2,AUC 0.822,KS 0.492|L: 0.059,Acc 99.0,AUC 0.755,KS 0.447|L: 0.328,Acc 99.2,AUC 0.805,KS 0.443\n",
      " 13. L: 0.050,Acc 99.2,AUC 0.825,KS 0.491|L: 0.062,Acc 99.0,AUC 0.759,KS 0.433|L: 0.394,Acc 99.2,AUC 0.789,KS 0.429\n",
      " 14. L: 0.051,Acc 99.2,AUC 0.834,KS 0.507|L: 0.059,Acc 99.0,AUC 0.762,KS 0.436|L: 0.314,Acc 99.2,AUC 0.819,KS 0.505\n",
      " 15. L: 0.050,Acc 99.2,AUC 0.835,KS 0.515|L: 0.060,Acc 99.0,AUC 0.760,KS 0.413|L: 0.353,Acc 99.2,AUC 0.829,KS 0.492\n",
      " 16. L: 0.050,Acc 99.2,AUC 0.824,KS 0.485|L: 0.061,Acc 99.0,AUC 0.769,KS 0.455|L: 0.379,Acc 99.2,AUC 0.810,KS 0.478\n",
      " 17. L: 0.051,Acc 99.2,AUC 0.842,KS 0.521|L: 0.060,Acc 99.0,AUC 0.751,KS 0.427|L: 0.326,Acc 99.2,AUC 0.798,KS 0.460\n",
      " 18. L: 0.049,Acc 99.2,AUC 0.835,KS 0.513|L: 0.059,Acc 99.0,AUC 0.771,KS 0.466|L: 0.314,Acc 99.2,AUC 0.809,KS 0.469\n",
      " 19. L: 0.051,Acc 99.2,AUC 0.843,KS 0.518|L: 0.060,Acc 99.0,AUC 0.758,KS 0.426|L: 0.352,Acc 99.2,AUC 0.799,KS 0.462\n",
      " 20. L: 0.050,Acc 99.2,AUC 0.843,KS 0.515|L: 0.061,Acc 99.0,AUC 0.757,KS 0.405|L: 0.376,Acc 99.2,AUC 0.805,KS 0.471\n",
      " 21. L: 0.050,Acc 99.2,AUC 0.841,KS 0.520|L: 0.061,Acc 99.0,AUC 0.756,KS 0.379|L: 0.365,Acc 99.2,AUC 0.809,KS 0.496\n",
      " 22. L: 0.049,Acc 99.2,AUC 0.845,KS 0.523|L: 0.060,Acc 99.0,AUC 0.754,KS 0.383|L: 0.361,Acc 99.2,AUC 0.807,KS 0.504\n",
      " 23. L: 0.049,Acc 99.2,AUC 0.851,KS 0.529|L: 0.061,Acc 99.0,AUC 0.756,KS 0.425|L: 0.376,Acc 99.2,AUC 0.802,KS 0.476\n",
      " 24. L: 0.049,Acc 99.2,AUC 0.851,KS 0.530|L: 0.061,Acc 99.0,AUC 0.762,KS 0.435|L: 0.369,Acc 99.2,AUC 0.809,KS 0.475\n",
      " 25. L: 0.048,Acc 99.2,AUC 0.856,KS 0.533|L: 0.062,Acc 99.0,AUC 0.749,KS 0.410|L: 0.364,Acc 99.2,AUC 0.793,KS 0.480\n",
      " 26. L: 0.048,Acc 99.2,AUC 0.836,KS 0.499|L: 0.061,Acc 99.0,AUC 0.769,KS 0.439|L: 0.374,Acc 99.2,AUC 0.813,KS 0.459\n",
      " 27. L: 0.049,Acc 99.2,AUC 0.850,KS 0.523|L: 0.061,Acc 99.0,AUC 0.753,KS 0.411|L: 0.364,Acc 99.2,AUC 0.810,KS 0.516\n",
      " 28. L: 0.048,Acc 99.2,AUC 0.832,KS 0.506|L: 0.061,Acc 99.0,AUC 0.765,KS 0.412|L: 0.381,Acc 99.2,AUC 0.815,KS 0.506\n",
      " 29. L: 0.048,Acc 99.2,AUC 0.859,KS 0.543|L: 0.061,Acc 99.0,AUC 0.749,KS 0.419|L: 0.336,Acc 99.2,AUC 0.789,KS 0.457\n",
      " 30. L: 0.047,Acc 99.2,AUC 0.869,KS 0.564|L: 0.065,Acc 99.0,AUC 0.732,KS 0.383|L: 0.387,Acc 99.2,AUC 0.759,KS 0.411\n",
      " 31. L: 0.048,Acc 99.2,AUC 0.867,KS 0.560|L: 0.062,Acc 99.0,AUC 0.736,KS 0.423|L: 0.353,Acc 99.2,AUC 0.783,KS 0.448\n",
      " 32. L: 0.047,Acc 99.2,AUC 0.865,KS 0.553|L: 0.063,Acc 99.0,AUC 0.742,KS 0.431|L: 0.393,Acc 99.2,AUC 0.787,KS 0.417\n",
      " 33. L: 0.047,Acc 99.2,AUC 0.872,KS 0.566|L: 0.062,Acc 99.0,AUC 0.740,KS 0.400|L: 0.337,Acc 99.2,AUC 0.782,KS 0.463\n",
      " 34. L: 0.047,Acc 99.2,AUC 0.871,KS 0.566|L: 0.062,Acc 99.0,AUC 0.744,KS 0.393|L: 0.371,Acc 99.2,AUC 0.788,KS 0.492\n",
      " 35. L: 0.047,Acc 99.2,AUC 0.870,KS 0.562|L: 0.062,Acc 99.0,AUC 0.745,KS 0.397|L: 0.363,Acc 99.2,AUC 0.794,KS 0.498\n",
      " 36. L: 0.047,Acc 99.2,AUC 0.864,KS 0.548|L: 0.062,Acc 99.0,AUC 0.740,KS 0.392|L: 0.352,Acc 99.2,AUC 0.797,KS 0.471\n",
      " 37. L: 0.046,Acc 99.2,AUC 0.866,KS 0.554|L: 0.061,Acc 99.0,AUC 0.758,KS 0.429|L: 0.364,Acc 99.2,AUC 0.796,KS 0.463\n",
      " 38. L: 0.046,Acc 99.2,AUC 0.875,KS 0.576|L: 0.065,Acc 99.0,AUC 0.744,KS 0.423|L: 0.393,Acc 99.2,AUC 0.792,KS 0.446\n",
      " 39. L: 0.046,Acc 99.2,AUC 0.873,KS 0.571|L: 0.060,Acc 99.0,AUC 0.751,KS 0.402|L: 0.346,Acc 99.2,AUC 0.790,KS 0.471\n",
      " 40. L: 0.046,Acc 99.2,AUC 0.878,KS 0.577|L: 0.062,Acc 99.0,AUC 0.749,KS 0.408|L: 0.371,Acc 99.2,AUC 0.779,KS 0.423\n",
      " 41. L: 0.046,Acc 99.2,AUC 0.881,KS 0.585|L: 0.063,Acc 99.0,AUC 0.743,KS 0.405|L: 0.381,Acc 99.2,AUC 0.787,KS 0.452\n",
      " 42. L: 0.046,Acc 99.2,AUC 0.878,KS 0.582|L: 0.063,Acc 99.0,AUC 0.740,KS 0.409|L: 0.383,Acc 99.2,AUC 0.791,KS 0.443\n",
      " 43. L: 0.046,Acc 99.2,AUC 0.878,KS 0.586|L: 0.063,Acc 99.0,AUC 0.746,KS 0.438|L: 0.389,Acc 99.2,AUC 0.794,KS 0.466\n",
      " 44. L: 0.046,Acc 99.2,AUC 0.880,KS 0.585|L: 0.062,Acc 99.0,AUC 0.747,KS 0.415|L: 0.362,Acc 99.2,AUC 0.790,KS 0.435\n",
      " 45. L: 0.046,Acc 99.2,AUC 0.882,KS 0.592|L: 0.063,Acc 99.0,AUC 0.745,KS 0.442|L: 0.375,Acc 99.2,AUC 0.785,KS 0.428\n",
      " 46. L: 0.046,Acc 99.2,AUC 0.873,KS 0.567|L: 0.062,Acc 99.0,AUC 0.747,KS 0.423|L: 0.367,Acc 99.2,AUC 0.791,KS 0.446\n",
      " 47. L: 0.045,Acc 99.2,AUC 0.883,KS 0.596|L: 0.063,Acc 99.0,AUC 0.741,KS 0.430|L: 0.370,Acc 99.2,AUC 0.792,KS 0.454\n",
      " 48. L: 0.046,Acc 99.2,AUC 0.881,KS 0.587|L: 0.062,Acc 99.0,AUC 0.741,KS 0.426|L: 0.369,Acc 99.2,AUC 0.791,KS 0.457\n",
      " 49. L: 0.045,Acc 99.2,AUC 0.877,KS 0.579|L: 0.062,Acc 99.0,AUC 0.744,KS 0.433|L: 0.364,Acc 99.2,AUC 0.791,KS 0.441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50. L: 0.046,Acc 99.2,AUC 0.870,KS 0.562|L: 0.062,Acc 99.0,AUC 0.746,KS 0.410|L: 0.369,Acc 99.2,AUC 0.789,KS 0.452\n",
      "Valid AUC: 0.771, Valid KS: 0.466\n",
      "Test AUC: 0.809, Test KS: 0.469\n",
      "fold 8\n",
      "  1. L: 0.104,Acc 99.0,AUC 0.754,KS 0.382|L: 0.066,Acc 99.1,AUC 0.709,KS 0.305|L: 0.189,Acc 99.2,AUC 0.704,KS 0.313\n",
      "  2. L: 0.057,Acc 99.2,AUC 0.786,KS 0.440|L: 0.060,Acc 99.1,AUC 0.720,KS 0.328|L: 0.163,Acc 99.2,AUC 0.746,KS 0.352\n",
      "  3. L: 0.055,Acc 99.2,AUC 0.793,KS 0.422|L: 0.062,Acc 99.1,AUC 0.741,KS 0.343|L: 0.172,Acc 99.2,AUC 0.768,KS 0.387\n",
      "  4. L: 0.054,Acc 99.2,AUC 0.793,KS 0.429|L: 0.061,Acc 99.1,AUC 0.726,KS 0.296|L: 0.167,Acc 99.2,AUC 0.768,KS 0.433\n",
      "  5. L: 0.053,Acc 99.2,AUC 0.796,KS 0.450|L: 0.057,Acc 99.1,AUC 0.743,KS 0.363|L: 0.148,Acc 99.2,AUC 0.757,KS 0.402\n",
      "  6. L: 0.055,Acc 99.1,AUC 0.798,KS 0.466|L: 0.058,Acc 99.1,AUC 0.737,KS 0.360|L: 0.154,Acc 99.2,AUC 0.745,KS 0.414\n",
      "  7. L: 0.053,Acc 99.2,AUC 0.752,KS 0.399|L: 0.063,Acc 99.1,AUC 0.685,KS 0.275|L: 0.173,Acc 99.2,AUC 0.715,KS 0.375\n",
      "  8. L: 0.053,Acc 99.2,AUC 0.808,KS 0.466|L: 0.058,Acc 99.1,AUC 0.739,KS 0.361|L: 0.151,Acc 99.2,AUC 0.780,KS 0.436\n",
      "  9. L: 0.051,Acc 99.2,AUC 0.815,KS 0.474|L: 0.057,Acc 99.1,AUC 0.753,KS 0.407|L: 0.151,Acc 99.2,AUC 0.765,KS 0.433\n",
      " 10. L: 0.051,Acc 99.2,AUC 0.814,KS 0.474|L: 0.058,Acc 99.1,AUC 0.747,KS 0.405|L: 0.136,Acc 99.2,AUC 0.763,KS 0.403\n",
      " 11. L: 0.050,Acc 99.2,AUC 0.815,KS 0.479|L: 0.061,Acc 99.1,AUC 0.727,KS 0.340|L: 0.169,Acc 99.2,AUC 0.744,KS 0.374\n",
      " 12. L: 0.051,Acc 99.2,AUC 0.824,KS 0.493|L: 0.058,Acc 99.1,AUC 0.746,KS 0.366|L: 0.156,Acc 99.2,AUC 0.751,KS 0.402\n",
      " 13. L: 0.051,Acc 99.2,AUC 0.820,KS 0.490|L: 0.057,Acc 99.1,AUC 0.757,KS 0.397|L: 0.142,Acc 99.2,AUC 0.752,KS 0.427\n",
      " 14. L: 0.051,Acc 99.2,AUC 0.823,KS 0.495|L: 0.059,Acc 99.1,AUC 0.746,KS 0.408|L: 0.160,Acc 99.2,AUC 0.756,KS 0.431\n",
      " 15. L: 0.050,Acc 99.2,AUC 0.831,KS 0.505|L: 0.057,Acc 99.1,AUC 0.760,KS 0.402|L: 0.146,Acc 99.2,AUC 0.763,KS 0.427\n",
      " 16. L: 0.051,Acc 99.2,AUC 0.820,KS 0.501|L: 0.058,Acc 99.1,AUC 0.749,KS 0.416|L: 0.147,Acc 99.2,AUC 0.764,KS 0.410\n",
      " 17. L: 0.050,Acc 99.2,AUC 0.833,KS 0.514|L: 0.057,Acc 99.1,AUC 0.755,KS 0.380|L: 0.146,Acc 99.2,AUC 0.759,KS 0.422\n",
      " 18. L: 0.050,Acc 99.2,AUC 0.839,KS 0.530|L: 0.058,Acc 99.1,AUC 0.761,KS 0.409|L: 0.165,Acc 99.2,AUC 0.756,KS 0.402\n",
      " 19. L: 0.050,Acc 99.2,AUC 0.839,KS 0.531|L: 0.058,Acc 99.1,AUC 0.756,KS 0.393|L: 0.159,Acc 99.2,AUC 0.760,KS 0.400\n",
      " 20. L: 0.050,Acc 99.2,AUC 0.846,KS 0.534|L: 0.057,Acc 99.1,AUC 0.749,KS 0.384|L: 0.145,Acc 99.2,AUC 0.758,KS 0.414\n",
      " 21. L: 0.050,Acc 99.2,AUC 0.823,KS 0.490|L: 0.058,Acc 99.1,AUC 0.730,KS 0.354|L: 0.156,Acc 99.2,AUC 0.758,KS 0.431\n",
      " 22. L: 0.049,Acc 99.2,AUC 0.844,KS 0.530|L: 0.057,Acc 99.1,AUC 0.749,KS 0.392|L: 0.153,Acc 99.2,AUC 0.752,KS 0.424\n",
      " 23. L: 0.048,Acc 99.2,AUC 0.848,KS 0.538|L: 0.060,Acc 99.1,AUC 0.741,KS 0.363|L: 0.169,Acc 99.2,AUC 0.752,KS 0.392\n",
      " 24. L: 0.048,Acc 99.2,AUC 0.845,KS 0.542|L: 0.058,Acc 99.1,AUC 0.742,KS 0.354|L: 0.155,Acc 99.2,AUC 0.756,KS 0.419\n",
      " 25. L: 0.049,Acc 99.2,AUC 0.855,KS 0.559|L: 0.057,Acc 99.1,AUC 0.741,KS 0.355|L: 0.152,Acc 99.2,AUC 0.764,KS 0.414\n",
      " 26. L: 0.049,Acc 99.2,AUC 0.854,KS 0.556|L: 0.058,Acc 99.1,AUC 0.744,KS 0.361|L: 0.157,Acc 99.2,AUC 0.766,KS 0.428\n",
      " 27. L: 0.048,Acc 99.2,AUC 0.854,KS 0.563|L: 0.060,Acc 99.1,AUC 0.751,KS 0.384|L: 0.170,Acc 99.2,AUC 0.764,KS 0.410\n",
      " 28. L: 0.048,Acc 99.2,AUC 0.860,KS 0.565|L: 0.060,Acc 99.1,AUC 0.745,KS 0.387|L: 0.167,Acc 99.2,AUC 0.761,KS 0.399\n",
      " 29. L: 0.048,Acc 99.2,AUC 0.860,KS 0.560|L: 0.059,Acc 99.1,AUC 0.748,KS 0.372|L: 0.162,Acc 99.2,AUC 0.751,KS 0.407\n",
      " 30. L: 0.048,Acc 99.2,AUC 0.863,KS 0.568|L: 0.059,Acc 99.1,AUC 0.740,KS 0.392|L: 0.163,Acc 99.2,AUC 0.749,KS 0.392\n",
      " 31. L: 0.048,Acc 99.2,AUC 0.864,KS 0.569|L: 0.058,Acc 99.1,AUC 0.743,KS 0.382|L: 0.162,Acc 99.2,AUC 0.746,KS 0.383\n",
      " 32. L: 0.048,Acc 99.2,AUC 0.867,KS 0.572|L: 0.058,Acc 99.1,AUC 0.743,KS 0.360|L: 0.157,Acc 99.2,AUC 0.750,KS 0.409\n",
      " 33. L: 0.047,Acc 99.2,AUC 0.872,KS 0.583|L: 0.063,Acc 99.1,AUC 0.743,KS 0.376|L: 0.185,Acc 99.2,AUC 0.752,KS 0.387\n",
      " 34. L: 0.047,Acc 99.2,AUC 0.851,KS 0.540|L: 0.059,Acc 99.1,AUC 0.735,KS 0.345|L: 0.156,Acc 99.2,AUC 0.759,KS 0.418\n",
      " 35. L: 0.047,Acc 99.2,AUC 0.871,KS 0.574|L: 0.059,Acc 99.1,AUC 0.749,KS 0.384|L: 0.166,Acc 99.2,AUC 0.747,KS 0.384\n",
      " 36. L: 0.047,Acc 99.2,AUC 0.848,KS 0.530|L: 0.060,Acc 99.1,AUC 0.725,KS 0.338|L: 0.164,Acc 99.2,AUC 0.752,KS 0.413\n",
      " 37. L: 0.046,Acc 99.2,AUC 0.867,KS 0.569|L: 0.059,Acc 99.1,AUC 0.745,KS 0.402|L: 0.164,Acc 99.2,AUC 0.753,KS 0.392\n",
      " 38. L: 0.046,Acc 99.2,AUC 0.857,KS 0.543|L: 0.060,Acc 99.1,AUC 0.733,KS 0.357|L: 0.169,Acc 99.2,AUC 0.744,KS 0.392\n",
      " 39. L: 0.046,Acc 99.2,AUC 0.873,KS 0.583|L: 0.058,Acc 99.1,AUC 0.742,KS 0.369|L: 0.163,Acc 99.2,AUC 0.744,KS 0.383\n",
      " 40. L: 0.047,Acc 99.2,AUC 0.880,KS 0.595|L: 0.059,Acc 99.1,AUC 0.741,KS 0.382|L: 0.168,Acc 99.2,AUC 0.740,KS 0.376\n",
      " 41. L: 0.046,Acc 99.2,AUC 0.878,KS 0.593|L: 0.060,Acc 99.1,AUC 0.747,KS 0.375|L: 0.175,Acc 99.2,AUC 0.747,KS 0.376\n",
      " 42. L: 0.046,Acc 99.2,AUC 0.879,KS 0.601|L: 0.059,Acc 99.1,AUC 0.746,KS 0.377|L: 0.165,Acc 99.2,AUC 0.744,KS 0.401\n",
      " 43. L: 0.046,Acc 99.2,AUC 0.884,KS 0.610|L: 0.059,Acc 99.1,AUC 0.744,KS 0.369|L: 0.175,Acc 99.2,AUC 0.743,KS 0.368\n",
      " 44. L: 0.046,Acc 99.2,AUC 0.878,KS 0.596|L: 0.060,Acc 99.1,AUC 0.741,KS 0.352|L: 0.173,Acc 99.2,AUC 0.741,KS 0.380\n",
      " 45. L: 0.046,Acc 99.2,AUC 0.882,KS 0.611|L: 0.059,Acc 99.1,AUC 0.741,KS 0.383|L: 0.166,Acc 99.2,AUC 0.747,KS 0.401\n",
      " 46. L: 0.046,Acc 99.2,AUC 0.884,KS 0.609|L: 0.059,Acc 99.1,AUC 0.742,KS 0.390|L: 0.166,Acc 99.2,AUC 0.746,KS 0.377\n",
      " 47. L: 0.045,Acc 99.2,AUC 0.884,KS 0.605|L: 0.060,Acc 99.1,AUC 0.744,KS 0.384|L: 0.171,Acc 99.2,AUC 0.750,KS 0.380\n",
      " 48. L: 0.046,Acc 99.2,AUC 0.887,KS 0.607|L: 0.059,Acc 99.1,AUC 0.743,KS 0.364|L: 0.171,Acc 99.2,AUC 0.749,KS 0.385\n",
      " 49. L: 0.045,Acc 99.2,AUC 0.886,KS 0.609|L: 0.060,Acc 99.1,AUC 0.743,KS 0.370|L: 0.172,Acc 99.2,AUC 0.748,KS 0.376\n",
      " 50. L: 0.045,Acc 99.2,AUC 0.885,KS 0.604|L: 0.060,Acc 99.1,AUC 0.742,KS 0.372|L: 0.171,Acc 99.2,AUC 0.748,KS 0.372\n",
      "Valid AUC: 0.749, Valid KS: 0.416\n",
      "Test AUC: 0.764, Test KS: 0.410\n",
      "fold 9\n",
      "  1. L: 0.117,Acc 99.0,AUC 0.740,KS 0.362|L: 0.052,Acc 99.3,AUC 0.657,KS 0.265|L: 0.294,Acc 99.2,AUC 0.743,KS 0.364\n",
      "  2. L: 0.060,Acc 99.1,AUC 0.772,KS 0.406|L: 0.048,Acc 99.3,AUC 0.742,KS 0.400|L: 0.216,Acc 99.2,AUC 0.749,KS 0.418\n",
      "  3. L: 0.059,Acc 99.1,AUC 0.770,KS 0.379|L: 0.053,Acc 99.3,AUC 0.736,KS 0.340|L: 0.327,Acc 99.2,AUC 0.740,KS 0.337\n",
      "  4. L: 0.058,Acc 99.1,AUC 0.775,KS 0.397|L: 0.051,Acc 99.3,AUC 0.737,KS 0.368|L: 0.311,Acc 99.2,AUC 0.747,KS 0.346\n",
      "  5. L: 0.055,Acc 99.1,AUC 0.792,KS 0.439|L: 0.047,Acc 99.3,AUC 0.751,KS 0.418|L: 0.273,Acc 99.2,AUC 0.751,KS 0.381\n",
      "  6. L: 0.055,Acc 99.1,AUC 0.799,KS 0.452|L: 0.046,Acc 99.3,AUC 0.745,KS 0.438|L: 0.226,Acc 99.2,AUC 0.728,KS 0.388\n",
      "  7. L: 0.054,Acc 99.1,AUC 0.779,KS 0.425|L: 0.047,Acc 99.3,AUC 0.713,KS 0.325|L: 0.222,Acc 99.2,AUC 0.747,KS 0.420\n",
      "  8. L: 0.053,Acc 99.1,AUC 0.812,KS 0.461|L: 0.045,Acc 99.3,AUC 0.767,KS 0.452|L: 0.251,Acc 99.2,AUC 0.763,KS 0.425\n",
      "  9. L: 0.053,Acc 99.1,AUC 0.815,KS 0.469|L: 0.047,Acc 99.3,AUC 0.778,KS 0.454|L: 0.293,Acc 99.2,AUC 0.771,KS 0.427\n",
      " 10. L: 0.054,Acc 99.1,AUC 0.822,KS 0.490|L: 0.044,Acc 99.3,AUC 0.783,KS 0.469|L: 0.242,Acc 99.2,AUC 0.775,KS 0.446\n",
      " 11. L: 0.053,Acc 99.1,AUC 0.822,KS 0.486|L: 0.044,Acc 99.3,AUC 0.771,KS 0.423|L: 0.241,Acc 99.2,AUC 0.776,KS 0.424\n",
      " 12. L: 0.061,Acc 99.1,AUC 0.798,KS 0.440|L: 0.046,Acc 99.3,AUC 0.748,KS 0.387|L: 0.229,Acc 99.2,AUC 0.771,KS 0.426\n",
      " 13. L: 0.054,Acc 99.1,AUC 0.817,KS 0.484|L: 0.046,Acc 99.3,AUC 0.765,KS 0.422|L: 0.269,Acc 99.2,AUC 0.784,KS 0.466\n",
      " 14. L: 0.054,Acc 99.1,AUC 0.815,KS 0.469|L: 0.044,Acc 99.3,AUC 0.776,KS 0.452|L: 0.248,Acc 99.2,AUC 0.779,KS 0.445\n",
      " 15. L: 0.053,Acc 99.1,AUC 0.818,KS 0.475|L: 0.045,Acc 99.3,AUC 0.768,KS 0.431|L: 0.258,Acc 99.2,AUC 0.776,KS 0.468\n",
      " 16. L: 0.053,Acc 99.1,AUC 0.814,KS 0.470|L: 0.045,Acc 99.3,AUC 0.756,KS 0.412|L: 0.241,Acc 99.2,AUC 0.775,KS 0.450\n",
      " 17. L: 0.052,Acc 99.1,AUC 0.827,KS 0.493|L: 0.045,Acc 99.3,AUC 0.758,KS 0.427|L: 0.231,Acc 99.2,AUC 0.773,KS 0.459\n",
      " 18. L: 0.052,Acc 99.1,AUC 0.825,KS 0.488|L: 0.046,Acc 99.3,AUC 0.765,KS 0.421|L: 0.268,Acc 99.2,AUC 0.771,KS 0.426\n",
      " 19. L: 0.051,Acc 99.1,AUC 0.827,KS 0.502|L: 0.046,Acc 99.3,AUC 0.763,KS 0.399|L: 0.235,Acc 99.2,AUC 0.788,KS 0.435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20. L: 0.051,Acc 99.1,AUC 0.832,KS 0.502|L: 0.045,Acc 99.3,AUC 0.762,KS 0.405|L: 0.246,Acc 99.2,AUC 0.783,KS 0.439\n",
      " 21. L: 0.051,Acc 99.1,AUC 0.841,KS 0.519|L: 0.045,Acc 99.3,AUC 0.758,KS 0.401|L: 0.233,Acc 99.2,AUC 0.786,KS 0.450\n",
      " 22. L: 0.051,Acc 99.1,AUC 0.839,KS 0.513|L: 0.044,Acc 99.3,AUC 0.772,KS 0.421|L: 0.234,Acc 99.2,AUC 0.778,KS 0.460\n",
      " 23. L: 0.051,Acc 99.1,AUC 0.839,KS 0.523|L: 0.045,Acc 99.3,AUC 0.757,KS 0.390|L: 0.246,Acc 99.2,AUC 0.774,KS 0.409\n",
      " 24. L: 0.051,Acc 99.1,AUC 0.844,KS 0.526|L: 0.046,Acc 99.3,AUC 0.755,KS 0.416|L: 0.234,Acc 99.2,AUC 0.780,KS 0.431\n",
      " 25. L: 0.051,Acc 99.1,AUC 0.839,KS 0.513|L: 0.045,Acc 99.3,AUC 0.766,KS 0.422|L: 0.234,Acc 99.2,AUC 0.791,KS 0.450\n",
      " 26. L: 0.050,Acc 99.1,AUC 0.845,KS 0.515|L: 0.045,Acc 99.3,AUC 0.757,KS 0.411|L: 0.244,Acc 99.2,AUC 0.784,KS 0.430\n",
      " 27. L: 0.050,Acc 99.1,AUC 0.853,KS 0.539|L: 0.046,Acc 99.3,AUC 0.758,KS 0.410|L: 0.268,Acc 99.2,AUC 0.765,KS 0.444\n",
      " 28. L: 0.050,Acc 99.1,AUC 0.853,KS 0.539|L: 0.046,Acc 99.3,AUC 0.759,KS 0.407|L: 0.235,Acc 99.2,AUC 0.777,KS 0.419\n",
      " 29. L: 0.050,Acc 99.1,AUC 0.853,KS 0.542|L: 0.046,Acc 99.3,AUC 0.756,KS 0.397|L: 0.240,Acc 99.2,AUC 0.770,KS 0.407\n",
      " 30. L: 0.050,Acc 99.1,AUC 0.861,KS 0.548|L: 0.046,Acc 99.3,AUC 0.751,KS 0.398|L: 0.244,Acc 99.2,AUC 0.771,KS 0.420\n",
      " 31. L: 0.050,Acc 99.2,AUC 0.859,KS 0.537|L: 0.045,Acc 99.3,AUC 0.754,KS 0.393|L: 0.244,Acc 99.2,AUC 0.761,KS 0.397\n",
      " 32. L: 0.049,Acc 99.1,AUC 0.861,KS 0.550|L: 0.045,Acc 99.3,AUC 0.765,KS 0.403|L: 0.251,Acc 99.2,AUC 0.773,KS 0.452\n",
      " 33. L: 0.049,Acc 99.1,AUC 0.858,KS 0.534|L: 0.045,Acc 99.3,AUC 0.757,KS 0.394|L: 0.255,Acc 99.2,AUC 0.780,KS 0.433\n",
      " 34. L: 0.049,Acc 99.1,AUC 0.867,KS 0.560|L: 0.046,Acc 99.3,AUC 0.758,KS 0.396|L: 0.248,Acc 99.2,AUC 0.775,KS 0.436\n",
      " 35. L: 0.049,Acc 99.1,AUC 0.868,KS 0.561|L: 0.046,Acc 99.3,AUC 0.756,KS 0.407|L: 0.255,Acc 99.2,AUC 0.779,KS 0.414\n",
      " 36. L: 0.049,Acc 99.1,AUC 0.871,KS 0.568|L: 0.045,Acc 99.3,AUC 0.755,KS 0.401|L: 0.243,Acc 99.2,AUC 0.783,KS 0.436\n",
      " 37. L: 0.049,Acc 99.1,AUC 0.871,KS 0.569|L: 0.046,Acc 99.3,AUC 0.758,KS 0.407|L: 0.236,Acc 99.2,AUC 0.779,KS 0.453\n",
      " 38. L: 0.048,Acc 99.1,AUC 0.872,KS 0.564|L: 0.046,Acc 99.3,AUC 0.749,KS 0.384|L: 0.245,Acc 99.2,AUC 0.775,KS 0.423\n",
      " 39. L: 0.049,Acc 99.1,AUC 0.867,KS 0.551|L: 0.045,Acc 99.3,AUC 0.761,KS 0.393|L: 0.233,Acc 99.2,AUC 0.775,KS 0.432\n",
      " 40. L: 0.049,Acc 99.1,AUC 0.866,KS 0.553|L: 0.045,Acc 99.3,AUC 0.765,KS 0.424|L: 0.246,Acc 99.2,AUC 0.783,KS 0.442\n",
      " 41. L: 0.049,Acc 99.1,AUC 0.877,KS 0.585|L: 0.046,Acc 99.3,AUC 0.758,KS 0.410|L: 0.253,Acc 99.2,AUC 0.773,KS 0.418\n",
      " 42. L: 0.048,Acc 99.1,AUC 0.876,KS 0.575|L: 0.046,Acc 99.3,AUC 0.754,KS 0.376|L: 0.242,Acc 99.2,AUC 0.773,KS 0.413\n",
      " 43. L: 0.047,Acc 99.1,AUC 0.871,KS 0.559|L: 0.045,Acc 99.3,AUC 0.754,KS 0.369|L: 0.251,Acc 99.2,AUC 0.780,KS 0.438\n",
      " 44. L: 0.048,Acc 99.1,AUC 0.828,KS 0.495|L: 0.045,Acc 99.3,AUC 0.741,KS 0.352|L: 0.246,Acc 99.2,AUC 0.780,KS 0.438\n",
      " 45. L: 0.047,Acc 99.1,AUC 0.878,KS 0.573|L: 0.047,Acc 99.3,AUC 0.754,KS 0.381|L: 0.249,Acc 99.2,AUC 0.772,KS 0.422\n",
      " 46. L: 0.048,Acc 99.1,AUC 0.857,KS 0.536|L: 0.045,Acc 99.3,AUC 0.745,KS 0.352|L: 0.236,Acc 99.2,AUC 0.786,KS 0.439\n",
      " 47. L: 0.047,Acc 99.2,AUC 0.878,KS 0.569|L: 0.046,Acc 99.3,AUC 0.752,KS 0.379|L: 0.246,Acc 99.2,AUC 0.770,KS 0.423\n",
      " 48. L: 0.047,Acc 99.2,AUC 0.880,KS 0.583|L: 0.046,Acc 99.3,AUC 0.759,KS 0.390|L: 0.244,Acc 99.2,AUC 0.768,KS 0.430\n",
      " 49. L: 0.048,Acc 99.1,AUC 0.880,KS 0.581|L: 0.046,Acc 99.3,AUC 0.759,KS 0.385|L: 0.248,Acc 99.2,AUC 0.767,KS 0.414\n",
      " 50. L: 0.047,Acc 99.2,AUC 0.877,KS 0.565|L: 0.046,Acc 99.3,AUC 0.755,KS 0.374|L: 0.242,Acc 99.2,AUC 0.772,KS 0.426\n",
      "Valid AUC: 0.783, Valid KS: 0.469\n",
      "Test AUC: 0.775, Test KS: 0.446\n",
      "fold 10\n",
      "  1. L: 0.101,Acc 99.1,AUC 0.773,KS 0.401|L: 0.060,Acc 99.2,AUC 0.717,KS 0.390|L: 0.122,Acc 99.2,AUC 0.715,KS 0.358\n",
      "  2. L: 0.059,Acc 99.1,AUC 0.800,KS 0.444|L: 0.050,Acc 99.2,AUC 0.760,KS 0.433|L: 0.095,Acc 99.2,AUC 0.733,KS 0.406\n",
      "  3. L: 0.056,Acc 99.1,AUC 0.801,KS 0.465|L: 0.056,Acc 99.2,AUC 0.757,KS 0.425|L: 0.088,Acc 99.2,AUC 0.722,KS 0.383\n",
      "  4. L: 0.055,Acc 99.2,AUC 0.794,KS 0.435|L: 0.051,Acc 99.2,AUC 0.777,KS 0.475|L: 0.105,Acc 99.2,AUC 0.728,KS 0.382\n",
      "  5. L: 0.056,Acc 99.1,AUC 0.783,KS 0.441|L: 0.051,Acc 99.2,AUC 0.751,KS 0.409|L: 0.100,Acc 99.2,AUC 0.695,KS 0.380\n",
      "  6. L: 0.054,Acc 99.2,AUC 0.813,KS 0.471|L: 0.049,Acc 99.2,AUC 0.757,KS 0.459|L: 0.095,Acc 99.2,AUC 0.731,KS 0.369\n",
      "  7. L: 0.056,Acc 99.1,AUC 0.798,KS 0.446|L: 0.051,Acc 99.2,AUC 0.760,KS 0.431|L: 0.102,Acc 99.2,AUC 0.724,KS 0.431\n",
      "  8. L: 0.053,Acc 99.2,AUC 0.811,KS 0.461|L: 0.049,Acc 99.2,AUC 0.765,KS 0.471|L: 0.096,Acc 99.2,AUC 0.715,KS 0.403\n",
      "  9. L: 0.053,Acc 99.2,AUC 0.825,KS 0.488|L: 0.049,Acc 99.2,AUC 0.778,KS 0.452|L: 0.096,Acc 99.2,AUC 0.741,KS 0.412\n",
      " 10. L: 0.054,Acc 99.1,AUC 0.812,KS 0.464|L: 0.049,Acc 99.2,AUC 0.779,KS 0.479|L: 0.094,Acc 99.2,AUC 0.734,KS 0.388\n",
      " 11. L: 0.051,Acc 99.2,AUC 0.825,KS 0.491|L: 0.050,Acc 99.2,AUC 0.770,KS 0.441|L: 0.100,Acc 99.2,AUC 0.725,KS 0.396\n",
      " 12. L: 0.052,Acc 99.2,AUC 0.832,KS 0.514|L: 0.051,Acc 99.2,AUC 0.776,KS 0.481|L: 0.089,Acc 99.2,AUC 0.739,KS 0.401\n",
      " 13. L: 0.056,Acc 99.1,AUC 0.825,KS 0.489|L: 0.051,Acc 99.2,AUC 0.769,KS 0.438|L: 0.089,Acc 99.2,AUC 0.731,KS 0.430\n",
      " 14. L: 0.053,Acc 99.2,AUC 0.826,KS 0.494|L: 0.049,Acc 99.2,AUC 0.774,KS 0.469|L: 0.091,Acc 99.2,AUC 0.744,KS 0.433\n",
      " 15. L: 0.051,Acc 99.2,AUC 0.829,KS 0.502|L: 0.050,Acc 99.2,AUC 0.778,KS 0.459|L: 0.091,Acc 99.2,AUC 0.747,KS 0.439\n",
      " 16. L: 0.051,Acc 99.2,AUC 0.838,KS 0.523|L: 0.050,Acc 99.2,AUC 0.773,KS 0.431|L: 0.095,Acc 99.2,AUC 0.743,KS 0.430\n",
      " 17. L: 0.050,Acc 99.2,AUC 0.842,KS 0.523|L: 0.051,Acc 99.2,AUC 0.771,KS 0.425|L: 0.092,Acc 99.2,AUC 0.736,KS 0.428\n",
      " 18. L: 0.051,Acc 99.2,AUC 0.841,KS 0.526|L: 0.049,Acc 99.2,AUC 0.775,KS 0.454|L: 0.096,Acc 99.2,AUC 0.730,KS 0.402\n",
      " 19. L: 0.052,Acc 99.2,AUC 0.841,KS 0.513|L: 0.049,Acc 99.2,AUC 0.771,KS 0.458|L: 0.097,Acc 99.2,AUC 0.731,KS 0.419\n",
      " 20. L: 0.050,Acc 99.2,AUC 0.840,KS 0.505|L: 0.049,Acc 99.2,AUC 0.772,KS 0.466|L: 0.091,Acc 99.2,AUC 0.737,KS 0.432\n",
      " 21. L: 0.050,Acc 99.2,AUC 0.839,KS 0.512|L: 0.049,Acc 99.2,AUC 0.785,KS 0.494|L: 0.097,Acc 99.2,AUC 0.737,KS 0.417\n",
      " 22. L: 0.054,Acc 99.1,AUC 0.837,KS 0.520|L: 0.049,Acc 99.2,AUC 0.786,KS 0.465|L: 0.097,Acc 99.2,AUC 0.734,KS 0.402\n",
      " 23. L: 0.051,Acc 99.2,AUC 0.849,KS 0.526|L: 0.049,Acc 99.2,AUC 0.781,KS 0.466|L: 0.097,Acc 99.2,AUC 0.727,KS 0.387\n",
      " 24. L: 0.050,Acc 99.2,AUC 0.860,KS 0.552|L: 0.049,Acc 99.2,AUC 0.773,KS 0.424|L: 0.097,Acc 99.2,AUC 0.717,KS 0.425\n",
      " 25. L: 0.050,Acc 99.2,AUC 0.855,KS 0.538|L: 0.049,Acc 99.2,AUC 0.779,KS 0.434|L: 0.096,Acc 99.2,AUC 0.729,KS 0.417\n",
      " 26. L: 0.050,Acc 99.2,AUC 0.859,KS 0.551|L: 0.049,Acc 99.2,AUC 0.775,KS 0.444|L: 0.093,Acc 99.2,AUC 0.722,KS 0.388\n",
      " 27. L: 0.050,Acc 99.2,AUC 0.863,KS 0.555|L: 0.049,Acc 99.2,AUC 0.782,KS 0.462|L: 0.094,Acc 99.2,AUC 0.732,KS 0.428\n",
      " 28. L: 0.049,Acc 99.2,AUC 0.863,KS 0.568|L: 0.050,Acc 99.2,AUC 0.776,KS 0.418|L: 0.102,Acc 99.2,AUC 0.734,KS 0.409\n",
      " 29. L: 0.050,Acc 99.2,AUC 0.857,KS 0.556|L: 0.049,Acc 99.2,AUC 0.787,KS 0.477|L: 0.095,Acc 99.2,AUC 0.733,KS 0.408\n",
      " 30. L: 0.049,Acc 99.1,AUC 0.870,KS 0.577|L: 0.050,Acc 99.2,AUC 0.763,KS 0.401|L: 0.094,Acc 99.2,AUC 0.724,KS 0.394\n",
      " 31. L: 0.048,Acc 99.2,AUC 0.855,KS 0.556|L: 0.049,Acc 99.2,AUC 0.783,KS 0.456|L: 0.093,Acc 99.2,AUC 0.739,KS 0.420\n",
      " 32. L: 0.049,Acc 99.2,AUC 0.869,KS 0.572|L: 0.050,Acc 99.2,AUC 0.783,KS 0.470|L: 0.101,Acc 99.2,AUC 0.723,KS 0.368\n",
      " 33. L: 0.049,Acc 99.2,AUC 0.869,KS 0.561|L: 0.050,Acc 99.2,AUC 0.777,KS 0.451|L: 0.099,Acc 99.2,AUC 0.732,KS 0.391\n",
      " 34. L: 0.048,Acc 99.2,AUC 0.878,KS 0.590|L: 0.051,Acc 99.2,AUC 0.771,KS 0.417|L: 0.101,Acc 99.2,AUC 0.709,KS 0.379\n",
      " 35. L: 0.048,Acc 99.2,AUC 0.873,KS 0.575|L: 0.050,Acc 99.2,AUC 0.779,KS 0.441|L: 0.094,Acc 99.2,AUC 0.729,KS 0.398\n",
      " 36. L: 0.048,Acc 99.2,AUC 0.875,KS 0.573|L: 0.051,Acc 99.2,AUC 0.770,KS 0.436|L: 0.100,Acc 99.2,AUC 0.719,KS 0.373\n",
      " 37. L: 0.048,Acc 99.2,AUC 0.879,KS 0.583|L: 0.052,Acc 99.2,AUC 0.773,KS 0.441|L: 0.107,Acc 99.2,AUC 0.717,KS 0.377\n",
      " 38. L: 0.047,Acc 99.2,AUC 0.881,KS 0.590|L: 0.050,Acc 99.2,AUC 0.772,KS 0.450|L: 0.096,Acc 99.2,AUC 0.716,KS 0.377\n",
      " 39. L: 0.048,Acc 99.2,AUC 0.880,KS 0.598|L: 0.051,Acc 99.2,AUC 0.771,KS 0.431|L: 0.103,Acc 99.2,AUC 0.716,KS 0.359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40. L: 0.047,Acc 99.2,AUC 0.883,KS 0.596|L: 0.051,Acc 99.2,AUC 0.774,KS 0.448|L: 0.097,Acc 99.2,AUC 0.715,KS 0.373\n",
      " 41. L: 0.047,Acc 99.2,AUC 0.862,KS 0.565|L: 0.049,Acc 99.2,AUC 0.782,KS 0.426|L: 0.093,Acc 99.2,AUC 0.735,KS 0.412\n",
      " 42. L: 0.047,Acc 99.2,AUC 0.886,KS 0.596|L: 0.051,Acc 99.2,AUC 0.767,KS 0.416|L: 0.102,Acc 99.2,AUC 0.713,KS 0.373\n",
      " 43. L: 0.047,Acc 99.2,AUC 0.873,KS 0.583|L: 0.051,Acc 99.2,AUC 0.778,KS 0.438|L: 0.100,Acc 99.2,AUC 0.726,KS 0.390\n",
      " 44. L: 0.047,Acc 99.2,AUC 0.881,KS 0.593|L: 0.050,Acc 99.2,AUC 0.773,KS 0.413|L: 0.095,Acc 99.2,AUC 0.724,KS 0.401\n",
      " 45. L: 0.046,Acc 99.2,AUC 0.890,KS 0.616|L: 0.052,Acc 99.2,AUC 0.759,KS 0.407|L: 0.100,Acc 99.2,AUC 0.712,KS 0.378\n",
      " 46. L: 0.047,Acc 99.2,AUC 0.890,KS 0.608|L: 0.051,Acc 99.2,AUC 0.761,KS 0.409|L: 0.098,Acc 99.2,AUC 0.715,KS 0.387\n",
      " 47. L: 0.047,Acc 99.2,AUC 0.889,KS 0.606|L: 0.051,Acc 99.2,AUC 0.765,KS 0.431|L: 0.098,Acc 99.2,AUC 0.712,KS 0.389\n",
      " 48. L: 0.047,Acc 99.2,AUC 0.890,KS 0.601|L: 0.051,Acc 99.2,AUC 0.766,KS 0.433|L: 0.099,Acc 99.2,AUC 0.712,KS 0.381\n",
      " 49. L: 0.047,Acc 99.2,AUC 0.885,KS 0.604|L: 0.051,Acc 99.2,AUC 0.771,KS 0.406|L: 0.098,Acc 99.2,AUC 0.720,KS 0.369\n",
      " 50. L: 0.046,Acc 99.2,AUC 0.888,KS 0.604|L: 0.051,Acc 99.2,AUC 0.766,KS 0.413|L: 0.097,Acc 99.2,AUC 0.716,KS 0.384\n",
      "Valid AUC: 0.785, Valid KS: 0.494\n",
      "Test AUC: 0.737, Test KS: 0.417\n"
     ]
    }
   ],
   "source": [
    "def loadTrain(filename):\n",
    "    X = []; y = []\n",
    "    with open(filename, 'r') as f:\n",
    "        line_count = 0\n",
    "        for line in f:\n",
    "            line_count += 1\n",
    "            if line_count == 1: continue\n",
    "            line = line.strip().split(',')\n",
    "            line = [float(x) for x in line]\n",
    "            X.append(line[:-1])\n",
    "            y.append(line[-1])\n",
    "    return np.array(X).astype('float32'), np.array(y).astype('int8')\n",
    "\n",
    "def loadTest(filename):\n",
    "    X = []\n",
    "    with open(filename, 'r') as f:\n",
    "        line_count = 0\n",
    "        for line in f:\n",
    "            line_count += 1\n",
    "            if line_count == 1: continue\n",
    "            line = line.strip().split(',')\n",
    "            line = [float(x) for x in line]\n",
    "            X.append(line)\n",
    "    return np.array(X).astype('float32')\n",
    "\n",
    "def subsample(X, y, sample_rate):\n",
    "    positive_index = np.argwhere(y == 0)\n",
    "    negtive_index = np.argwhere(y == 1)\n",
    "    random.shuffle(positive_index)\n",
    "    sampled_index = positive_index[0: sample_rate * len(negtive_index)]\n",
    "    index = np.vstack((sampled_index, negtive_index)).squeeze()\n",
    "    return X[index], y[index]\n",
    "\n",
    "def deleteMissLotFeature(X, y, rate = 0.7):\n",
    "    empty_flag = (X == -2) + (X == -1)\n",
    "    empty_rate = empty_flag.sum(axis = 0) * 1.0 / empty_flag.shape[0]\n",
    "    feature_index = np.argwhere(empty_rate <= rate)\n",
    "    feature_index = [x[0] for x in feature_index]\n",
    "    new_X = X[:, feature_index]\n",
    "    return new_X\n",
    "\n",
    "def deleteMissLotSample(X, y, rate = 0.4):\n",
    "    empty_flag = (X == -2) + (X == -1)\n",
    "    empty_rate = empty_flag.sum(axis = 1) * 1.0 / empty_flag.shape[1]\n",
    "    sample_index = np.argwhere(empty_rate <= rate)\n",
    "    sample_index = [x[0] for x in sample_index]\n",
    "    new_X = X[sample_index]\n",
    "    new_y = y[sample_index]\n",
    "    return new_X, new_y\n",
    "\n",
    "def featureSelection(X, y):\n",
    "    sel = feature_selection.VarianceThreshold(threshold = 0)\n",
    "    X = sel.fit_transform(X)\n",
    "    return X, y\n",
    "\n",
    "def splitDataset(X, y):\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
    "    valid_X, test_X, valid_y, test_y = train_test_split(test_X, test_y, test_size = 0.5)\n",
    "    \n",
    "    return train_X, train_y, valid_X, valid_y, test_X, test_y\n",
    "\n",
    "def addFeature(func, X):\n",
    "    feature = func(X)\n",
    "    X = np.column_stack((X, feature))\n",
    "    return X\n",
    "\n",
    "def missingRate(X):\n",
    "    empty_flag = (X == -2) + (X == -1)\n",
    "    empty_rate = empty_flag.sum(axis = 1) * 1.0 / empty_flag.shape[1]\n",
    "    return empty_rate\n",
    "\n",
    "def param():\n",
    "    params = {\n",
    "        'lr': 0.002,\n",
    "        'bs': 64,\n",
    "        'ctx': [0],\n",
    "        'optimizer': 'adam',\n",
    "        'epochs': 50,\n",
    "        'sample_rate': 100,\n",
    "        'feature_delete_rate': 1,\n",
    "        'sample_delete_rate': 1,\n",
    "        'model_path': 'model/',\n",
    "        'wd': 0.0000,\n",
    "        'model': CNN,\n",
    "#         'model': furuizeModel,\n",
    "        'nfold': 10,\n",
    "        'fp_weight': 10,\n",
    "        'fn_weight': 5,\n",
    "        'tp_tn_weight': 1,\n",
    "        'prefix': 'best-model-cost-sensitive'\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def main():\n",
    "    train_file = 'X_final.csv'\n",
    "    train_X = pd.read_csv(train_file)\n",
    "    X = train_X.as_matrix()\n",
    "    \n",
    "#     train_file = 'train_feature_selection.csv'\n",
    "    params = param()\n",
    "    label_data = pd.read_csv(\"y_final.csv\")\n",
    "    label = label_data.as_matrix()\n",
    "    y = label[:,-1]\n",
    "    #X, y = loadTrain(train_file)\n",
    "    print(type(X))\n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "#     X = addFeature(missingRate, X)\n",
    "    \n",
    "    X = deleteMissLotFeature(X, y, rate = params['feature_delete_rate'])\n",
    "    print('After feature delete: ', X.shape)\n",
    "    X, y = deleteMissLotSample(X, y, rate = params['sample_delete_rate'])\n",
    "    print('After Sample delete:', X.shape)\n",
    "    X, y = featureSelection(X, y)\n",
    "    print('After Feature Selection: ', X.shape, y.shape)\n",
    "    X = np.expand_dims(X, axis = 1)\n",
    "    \n",
    "    nfold = params['nfold']\n",
    "    skf = StratifiedKFold(n_splits = nfold)\n",
    "    \n",
    "    fold = 1\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print('fold %d' % fold)\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 1.0 / (nfold - 1))\n",
    "        X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "#         train_X, train_y = subsample(train_X, train_y, params['sample_rate'])\n",
    "    \n",
    "        mu = X_train.mean(axis = (0, 1), keepdims = True)\n",
    "        std = X_train.std(axis = (0, 1), keepdims = True)\n",
    "    \n",
    "        X_train = (X_train - mu) / std\n",
    "        X_valid = (X_valid - mu) / std\n",
    "        X_test = (X_test - mu) / std\n",
    "    \n",
    "        train(fold, X_train, y_train, X_valid, y_valid, X_test, y_test, params)\n",
    "    \n",
    "        valid_auc, valid_ks, valid_pred_prob = predict(fold, params, X_valid, y_valid)\n",
    "        test_auc, test_ks, test_pred_prob = predict(fold, params, X_test, y_test)\n",
    "        print('Valid AUC: %.3f, Valid KS: %.3f' % (valid_auc, valid_ks))\n",
    "        print('Test AUC: %.3f, Test KS: %.3f' % (test_auc, test_ks))\n",
    "        fold += 1\n",
    "#     save(valid_pred_prob)\n",
    "#     save(test_pred_prob)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blindEvaluate():\n",
    "    test_file = 'test.csv'\n",
    "    params = param()\n",
    "    test_X = loadTest(test_file)\n",
    "    test_X = np.expand_dims(test_X, axis = 1)\n",
    "    test_pred_label, test_pred_prob = blindPredict(params, test_X)\n",
    "    return test_pred_label, test_pred_prob\n",
    "\n",
    "# pred_label, pred_prob = blindEvaluate()\n",
    "# with open('predict-probability.csv', 'w') as f:\n",
    "#     f.write('label,good-prob,bad-prob\\n')\n",
    "#     for label, prob in zip(pred_label, pred_prob):\n",
    "#         f.write('%d,%d,%d\\n' % (label, prob, 1 - prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
