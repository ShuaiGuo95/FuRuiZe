{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import PredefinedSplit\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ks_score(prob, label):\n",
    "    '''\n",
    "    计算ks得分\n",
    "    :param pro: 属于坏人的概率\n",
    "    :param label: 真实标签\n",
    "    :return: ks得分\n",
    "    '''\n",
    "    df = pd.DataFrame(data = {'label': label, 'prob': prob})\n",
    "    df['prob'] = df['prob'].map(lambda x: round(x, 3))\n",
    "    total = pd.DataFrame({'total': df.groupby('prob')['label'].count()})\n",
    "    bad = pd.DataFrame({'bad': df.groupby('prob')['label'].sum()})\n",
    "    all_data = total.merge(bad, how = 'left', left_index = True, right_index = True)\n",
    "    all_data['good'] = all_data['total'] - all_data['bad']\n",
    "    all_data.reset_index(inplace = True)\n",
    "    all_data['goodCumPer'] = all_data['good'].cumsum() / all_data['good'].sum()\n",
    "    all_data['badCumPer'] = all_data['bad'].cumsum() / all_data['bad'].sum()\n",
    "    KS_m = all_data.apply(lambda x: x.goodCumPer - x.badCumPer, axis = 1)\n",
    "    return max(KS_m)\n",
    "\n",
    "def my_scoring(self, X, y, sample_weight=None):\n",
    "    scoring_prob = self.predict_proba(X)[:, 1]\n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y, scoring_prob)\n",
    "    auc = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "    ks = get_ks_score(scoring_prob, y)\n",
    "    #print(X.shape)\n",
    "    #score_need = 2*auc*ks/(auc + ks)\n",
    "    score_need = (auc + ks)\n",
    "    return ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0.851312199018 0.552354978712\n",
      "0.809249284941 0.508107220161\n",
      "0.810423293862 0.520493729056\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./cmh_level/level_6_median.csv')\n",
    "data.values.shape\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logitraw',\n",
    "    'eval_metric': 'auc',\n",
    "    \n",
    "    'eta': 0.1,# learning rate 0.2 --\n",
    "    \n",
    "    'scale_pos_weight': 34, #2 --\n",
    "    \n",
    "    'max_depth': 2,# --\n",
    "    'min_child_weight': 1.5, #1.6 \n",
    "    'gamma': 0.5, #越大算法越保守 ??\n",
    "    'subsample': 0.5, #每棵树随机采样比例 --\n",
    "    'colsample_bytree': 0.9, #每棵树随机采样的列数的占比 2 --\n",
    "    \n",
    "    'max_delta_step': 1, # 每棵树权重改变的最大步长 可用于类别不平衡 logisticregresion --\n",
    "\n",
    "    'alpha': 0.9, #l1正则化参数 --\n",
    "    'lambda': 0.6, #l2正则化参数 --\n",
    "\n",
    "    'silent': 0,\n",
    "}\n",
    "train_auc, train_ks = [], []\n",
    "val_auc, val_ks = [], []\n",
    "test_auc, test_ks = [], []\n",
    "\n",
    "data_y = data.pop('label').as_matrix()\n",
    "data_X = data.as_matrix()\n",
    "i = 0\n",
    "\n",
    "for j in range(1):\n",
    "    for X_train, X_val, X_test, y_train, y_val, y_test in utils.kfold(data_X, data_y, num_fold = 10):\n",
    "        print(i)\n",
    "        i = i + 1\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        min_max_scaler.fit(X_train)\n",
    "        X_train = min_max_scaler.transform(X_train)\n",
    "        X_val = min_max_scaler.transform(X_val)\n",
    "        X_test = min_max_scaler.transform(X_test)\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train) # xgboost data style\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "        \n",
    "        xg_model = xgb.train(params, dtrain, num_boost_round=84) #10-150\n",
    "        \n",
    "        y_train_pred_prob = xg_model.predict(dtrain)\n",
    "        y_val_pred_prob = xg_model.predict(dval)\n",
    "        y_test_pred_prob = xg_model.predict(dtest)\n",
    "        temp_auc, temp_ks = utils.model_key_performance(y_train_pred_prob, y_train)\n",
    "        train_auc.append(temp_auc)\n",
    "        train_ks.append(temp_ks)\n",
    "        temp_auc, temp_ks = utils.model_key_performance(y_val_pred_prob, y_val)\n",
    "        val_auc.append(temp_auc)\n",
    "        val_ks.append(temp_ks)\n",
    "        temp_auc, temp_ks = utils.model_key_performance(y_test_pred_prob, y_test)\n",
    "        test_auc.append(temp_auc)\n",
    "        test_ks.append(temp_ks)\n",
    "\n",
    "print(np.mean(train_auc), np.mean(train_ks))\n",
    "print(np.mean(val_auc), np.mean(val_ks))\n",
    "print(np.mean(test_auc), np.mean(test_ks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851312199018 0.552354978712\n",
      "0.809249284941 0.508107220161\n",
      "0.810423293862 0.520493729056\n"
     ]
    }
   ],
   "source": [
    "#best 0 1\n",
    "print(np.mean(train_auc), np.mean(train_ks))\n",
    "print(np.mean(val_auc), np.mean(val_ks))\n",
    "print(np.mean(test_auc), np.mean(test_ks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.54474756320438622,\n",
       " 0.4338563592294935,\n",
       " 0.55427988263809169,\n",
       " 0.52532790592492085,\n",
       " 0.51889735471825027,\n",
       " 0.57165222836864626,\n",
       " 0.48300455763142336,\n",
       " 0.55350868037435208,\n",
       " 0.48001832330190541,\n",
       " 0.53964443516682326]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851264940686 0.552949281894\n",
      "0.809640006571 0.510001642703\n",
      "0.811647289066 0.52492858787\n"
     ]
    }
   ],
   "source": [
    "print((np.sum(train_auc)-np.max(train_auc)-np.min(train_auc))/8, (np.sum(train_ks)-np.max(train_ks)-np.min(train_ks))/8)\n",
    "print((np.sum(val_auc)-np.max(val_auc)-np.min(val_auc))/8, (np.sum(val_ks)-np.max(val_ks)-np.min(val_ks))/8)\n",
    "print((np.sum(test_auc)-np.max(test_auc)-np.min(test_auc))/8, (np.sum(test_ks)-np.max(test_ks)-np.min(test_ks))/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logitraw',\n",
    "    'eval_metric': 'auc',\n",
    "    \n",
    "    'eta': 0.1,# learning rate 0.2 --\n",
    "    \n",
    "    'scale_pos_weight': 34, #2 --\n",
    "    \n",
    "    'max_depth': 2,# --\n",
    "    'min_child_weight': 1.5, #1.6 ??\n",
    "    'gamma': 0.5, #越大算法越保守 ??\n",
    "    'subsample': 0.5, #每棵树随机采样比例 --\n",
    "    'colsample_bytree': 0.9, #每棵树随机采样的列数的占比 2 --\n",
    "    \n",
    "    'max_delta_step': 1, # 每棵树权重改变的最大步长 可用于类别不平衡 logisticregresion --\n",
    "\n",
    "    'alpha': 0.9, #l1正则化参数 --\n",
    "    'lambda': 0.6, #l2正则化参数 --\n",
    "\n",
    "    'silent': 0,\n",
    "}\n",
    "num_boost_round=84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j = 0\n",
      "j = 1\n",
      "j = 2\n",
      "j = 3\n",
      "j = 4\n",
      "j = 5\n",
      "j = 6\n",
      "j = 7\n",
      "j = 8\n",
      "j = 9\n",
      "j = 10\n",
      "j = 11\n",
      "j = 12\n",
      "j = 13\n",
      "j = 14\n",
      "j = 15\n",
      "j = 16\n",
      "j = 17\n",
      "j = 18\n",
      "j = 19\n",
      "0.83384344715 0.520424270436\n",
      "0.793066585199 0.471246688254\n",
      "0.793445098299 0.474210050747\n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('./cmh_level/level_6_median.csv')\n",
    "# params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:logistic',\n",
    "#     'eval_metric': 'auc',\n",
    "    \n",
    "#     'eta': 0.1,# learning rate\n",
    "    \n",
    "#     'scale_pos_weight': 100,\n",
    "    \n",
    "#     'max_depth': 2,\n",
    "#     'min_child_weight': 1.5,\n",
    "#     'gamma': 0.5, #越大算法越保守\n",
    "#     'subsample': 0.5, #每棵树随机采样比例\n",
    "#     'colsample_bytree': 0.8, #每棵树随机采样的列数的占比\n",
    "    \n",
    "#     'max_delta_step': 1, # 每棵树权重改变的最大步长 可用于类别不平衡 logisticregresion\n",
    "\n",
    "#     'alpha': 0.8, #l1正则化参数\n",
    "#     'lambda': 0.6, #l2正则化参数\n",
    "\n",
    "#     'silent': 0,\n",
    "# }\n",
    "# train_auc, train_ks = [], []\n",
    "# val_auc, val_ks = [], []\n",
    "# test_auc, test_ks = [], []\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# for j in range(20):\n",
    "#     print('j =', j)\n",
    "#     X_train, X_val, X_test, y_train, y_val, y_test = utils.train_val_test_split(data, train_size, val_size, test_size, \n",
    "#                                                                             random_state=None, time_factors=False)\n",
    "#     min_max_scaler = MinMaxScaler()\n",
    "#     min_max_scaler.fit(X_train)\n",
    "#     X_train = min_max_scaler.transform(X_train)\n",
    "#     X_val = min_max_scaler.transform(X_val)\n",
    "#     X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "#     dtrain = xgb.DMatrix(X_train, label=y_train) # xgboost data style\n",
    "#     dval = xgb.DMatrix(X_val, label=y_val)\n",
    "#     dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "#     xg_model = xgb.train(params, dtrain, num_boost_round=50)\n",
    "    \n",
    "#     y_train_pred_prob = xg_model.predict(dtrain)\n",
    "#     y_val_pred_prob = xg_model.predict(dval)\n",
    "#     y_test_pred_prob = xg_model.predict(dtest)\n",
    "#     temp_auc, temp_ks = utils.model_key_performance(y_train_pred_prob, y_train)\n",
    "#     train_auc.append(temp_auc)\n",
    "#     train_ks.append(temp_ks)\n",
    "#     temp_auc, temp_ks = utils.model_key_performance(y_val_pred_prob, y_val)\n",
    "#     val_auc.append(temp_auc)\n",
    "#     val_ks.append(temp_ks)\n",
    "#     temp_auc, temp_ks = utils.model_key_performance(y_test_pred_prob, y_test)\n",
    "#     test_auc.append(temp_auc)\n",
    "#     test_ks.append(temp_ks)\n",
    "\n",
    "# print(np.mean(train_auc), np.mean(train_ks))\n",
    "# print(np.mean(val_auc), np.mean(val_ks))\n",
    "# print(np.mean(test_auc), np.mean(test_ks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
