{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import PredefinedSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ks_score(prob, label):\n",
    "    '''\n",
    "    计算ks得分\n",
    "    :param pro: 属于坏人的概率\n",
    "    :param label: 真实标签\n",
    "    :return: ks得分\n",
    "    '''\n",
    "    df = pd.DataFrame(data = {'label': label, 'prob': prob})\n",
    "    df['prob'] = df['prob'].map(lambda x: round(x, 3))\n",
    "    total = pd.DataFrame({'total': df.groupby('prob')['label'].count()})\n",
    "    bad = pd.DataFrame({'bad': df.groupby('prob')['label'].sum()})\n",
    "    all_data = total.merge(bad, how = 'left', left_index = True, right_index = True)\n",
    "    all_data['good'] = all_data['total'] - all_data['bad']\n",
    "    all_data.reset_index(inplace = True)\n",
    "    all_data['goodCumPer'] = all_data['good'].cumsum() / all_data['good'].sum()\n",
    "    all_data['badCumPer'] = all_data['bad'].cumsum() / all_data['bad'].sum()\n",
    "    KS_m = all_data.apply(lambda x: x.goodCumPer - x.badCumPer, axis = 1)\n",
    "    return max(KS_m)\n",
    "\n",
    "def my_scoring(self, X, y, sample_weight=None):\n",
    "    scoring_prob = self.predict_proba(X)[:, 1]\n",
    "    false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y, scoring_prob)\n",
    "    auc = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "    ks = get_ks_score(scoring_prob, y)\n",
    "    #print(X.shape)\n",
    "    #score_need = 2*auc*ks/(auc + ks)\n",
    "    score_need = (auc + ks)\n",
    "    return ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79054, 123)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./cmh_level/level_6.csv')\n",
    "data.values.shape\n",
    "\n",
    "# X_train = pd.read_csv('./time_split/train_data_6_10_feature_selected_median_level_6.csv')\n",
    "# X_val = pd.read_csv('./time_split/val_data_11_feature_selected_median_level_6.csv')\n",
    "# X_test = pd.read_csv('./time_split/test_data_feature_selected_12_median_level_6.csv')\n",
    "# y_train = X_train.pop('label').as_matrix()\n",
    "# y_val = X_val.pop('label').as_matrix()\n",
    "# y_test = X_test.pop('label').as_matrix()\n",
    "# X_train = X_train.as_matrix()\n",
    "# X_val = X_val.as_matrix()\n",
    "# X_test = X_test.as_matrix()\n",
    "\n",
    "# X_train = pd.read_csv('./cmh_level/level6_onehot/X_train.csv').as_matrix()\n",
    "# X_val = pd.read_csv('./cmh_level/level6_onehot/X_val.csv').as_matrix()\n",
    "# X_test = pd.read_csv('./cmh_level/level6_onehot/X_test.csv').as_matrix()\n",
    "# y_train = pd.read_csv('./cmh_level/level6_onehot/y_train.csv').as_matrix().T[0]\n",
    "# y_val = pd.read_csv('./cmh_level/level6_onehot/y_val.csv').as_matrix().T[0]\n",
    "# y_test = pd.read_csv('./cmh_level/level6_onehot/y_test.csv').as_matrix().T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 58008, 1: 491}) Counter({0: 10191, 1: 86}) Counter({0: 10192, 1: 86})\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.74\n",
    "val_size = 0.13\n",
    "test_size = 0.13\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = utils.train_val_test_split(data, train_size, val_size, test_size, \n",
    "                                                                            random_state=0, time_factors=False)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(X_train)\n",
    "X_train = min_max_scaler.transform(X_train)\n",
    "X_val = min_max_scaler.transform(X_val)\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "print(Counter(y_train), Counter(y_val), Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train = pd.DataFrame(X_train)\n",
    "# X_test = pd.DataFrame(X_test)\n",
    "# X_val = pd.DataFrame(X_val)\n",
    "# y_train = pd.DataFrame(y_train)\n",
    "# y_test = pd.DataFrame(y_test)\n",
    "# y_val = pd.DataFrame(y_val)\n",
    "\n",
    "# X_train.to_csv('X_train.csv', index = False)\n",
    "# X_test.to_csv('X_test.csv', index = False)\n",
    "# X_val.to_csv('X_val.csv', index = False)\n",
    "# y_train.to_csv('y_train.csv', index = False)\n",
    "# y_test.to_csv('y_test.csv', index = False)\n",
    "# y_val.to_csv('y_val.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7999599549121974, 0.50095378043883021)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#原始逻辑回归baseline\n",
    "lr = LogisticRegression(C=0.1, class_weight={1:30})\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_pred_prob = lr.predict_proba(X_train)[:, 1]\n",
    "y_val_pred_prob = lr.predict_proba(X_val)[:, 1]\n",
    "y_test_pred_prob = lr.predict_proba(X_test)[:, 1]\n",
    "utils.model_key_performance(y_train_pred_prob, y_train)\n",
    "utils.model_key_performance(y_val_pred_prob, y_val)\n",
    "utils.model_key_performance(y_test_pred_prob, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#原始xgboost baseline \n",
    "#level_6的最佳参数\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train) # xgboost data style\n",
    "# dval = xgb.DMatrix(X_val, label=y_val)\n",
    "# dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "# params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:logitraw',\n",
    "#     'eval_metric': 'auc',\n",
    "#     'max_depth': 2,\n",
    "#     'max_delta_step': 3,\n",
    "#     'lambda': 0.8,\n",
    "#     'subsample': 0.4,\n",
    "#     'colsample_bytree': 1,\n",
    "#     'min_child_weight': 1.5,\n",
    "#     'eta': 0.2,\n",
    "#     'silent': 0,\n",
    "#     'scale_pos_weight': 2,\n",
    "#     'gamma': 2\n",
    "# }\n",
    "# # watchlist = [(dtrain, 'train'), (dval, 'val'), (dtest, 'test')]\n",
    "# # train_val_features = np.concatenate((X_train, X_val), axis = 0)\n",
    "# # train_val_labels = np.concatenate((y_train, y_val), axis = 0)\n",
    "# # test_fold = np.zeros(train_val_features.shape[0])\n",
    "# # test_fold[:X_train_need[i].shape[0]] = -1\n",
    "# # ps = PredefinedSplit(test_fold = test_fold)\n",
    "\n",
    "# # xg_model = GridSearchCV(estimator=LogisticRegression(), param_grid=params, \n",
    "# #                      scoring=my_scoring, n_jobs=-1, cv=ps, verbose=0)\n",
    "# # model.fit(train_val_features, train_val_labels)\n",
    "# xg_model = xgb.train(params, dtrain, num_boost_round=60)\n",
    "\n",
    "# y_train_pred_prob = xg_model.predict(dtrain)\n",
    "# y_val_pred_prob = xg_model.predict(dval)\n",
    "# y_test_pred_prob = xg_model.predict(dtest)\n",
    "# utils.model_key_performance(y_train_pred_prob, y_train)\n",
    "# utils.model_key_performance(y_val_pred_prob, y_val)\n",
    "# utils.model_key_performance(y_test_pred_prob, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#原始xgboost baseline\n",
    "#level_6_median的最佳参数\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train) # xgboost data style\n",
    "# dval = xgb.DMatrix(X_val, label=y_val)\n",
    "# dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "# params = {\n",
    "#     'booster': 'gbtree',\n",
    "#     'objective': 'binary:logitraw',\n",
    "#     'eval_metric': 'auc',\n",
    "#     'max_depth': 2,\n",
    "#     'max_delta_step': 2,\n",
    "#     'lambda': 0.6,\n",
    "#     'subsample': 0.5,\n",
    "#     'colsample_bytree': 0.8,\n",
    "#     'min_child_weight': 1.6,\n",
    "#     'eta': 0.2,\n",
    "#     'silent': 0,\n",
    "#     'scale_pos_weight': 2,\n",
    "#     'gamma': 2\n",
    "# }\n",
    "# # watchlist = [(dtrain, 'train'), (dval, 'val'), (dtest, 'test')]\n",
    "# # train_val_features = np.concatenate((X_train, X_val), axis = 0)\n",
    "# # train_val_labels = np.concatenate((y_train, y_val), axis = 0)\n",
    "# # test_fold = np.zeros(train_val_features.shape[0])\n",
    "# # test_fold[:X_train_need[i].shape[0]] = -1\n",
    "# # ps = PredefinedSplit(test_fold = test_fold)\n",
    "\n",
    "# # xg_model = GridSearchCV(estimator=LogisticRegression(), param_grid=params, \n",
    "# #                      scoring=my_scoring, n_jobs=-1, cv=ps, verbose=0)\n",
    "# # model.fit(train_val_features, train_val_labels)\n",
    "# xg_model = xgb.train(params, dtrain, num_boost_round=71)\n",
    "\n",
    "# y_train_pred_prob = xg_model.predict(dtrain)\n",
    "# y_val_pred_prob = xg_model.predict(dval)\n",
    "# y_test_pred_prob = xg_model.predict(dtest)\n",
    "# utils.model_key_performance(y_train_pred_prob, y_train)\n",
    "# utils.model_key_performance(y_val_pred_prob, y_val)\n",
    "# utils.model_key_performance(y_test_pred_prob, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#集成学习分割数据\n",
    "X_train_1 = X_train[y_train == 1]\n",
    "y_train_1 = y_train[y_train == 1]\n",
    "X_train_0 = X_train[y_train == 0]\n",
    "y_train_0 = y_train[y_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 7\n",
    "step_size = X_train_0.shape[0] // k\n",
    "\n",
    "X_train_need = []\n",
    "y_train_need = []\n",
    "for i in range(k):\n",
    "    tmp_x = X_train_0[i*step_size:min(X_train_0.shape[0]-1, i*step_size+step_size)]\n",
    "    tmp_y = y_train_0[i*step_size:min(X_train_0.shape[0]-1, i*step_size+step_size)]\n",
    "    X_train_need.append(np.concatenate((X_train_1, tmp_x), axis=0))\n",
    "    y_train_need.append(np.concatenate((y_train_1, tmp_y), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_params = [i/10 for i in range(1, 10)] + [i for i in range(1, 10, 1)] + [i for i in range(10, 100, 10)]\n",
    "cw_params = [i for i in range(1, 10, 1)] + [i for i in range(10, 100, 10)]\n",
    "params = {\n",
    "    'C': C_params,\n",
    "    'class_weight': [{1:w} for w in cw_params],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0 \n",
      "\n",
      "{'class_weight': {1: 10}, 'C': 0.2}\n",
      "0.478019821411\n",
      "\n",
      "\n",
      "i =  1 \n",
      "\n",
      "{'class_weight': {1: 9}, 'C': 0.2}\n",
      "0.490383671867\n",
      "\n",
      "\n",
      "i =  2 \n",
      "\n",
      "{'class_weight': {1: 5}, 'C': 0.3}\n",
      "0.490972426651\n",
      "\n",
      "\n",
      "i =  3 \n",
      "\n",
      "{'class_weight': {1: 10}, 'C': 0.7}\n",
      "0.470022568933\n",
      "\n",
      "\n",
      "i =  4 \n",
      "\n",
      "{'class_weight': {1: 7}, 'C': 0.2}\n",
      "0.488715533314\n",
      "\n",
      "\n",
      "i =  5 \n",
      "\n",
      "{'class_weight': {1: 10}, 'C': 0.2}\n",
      "0.488273967226\n",
      "\n",
      "\n",
      "i =  6 \n",
      "\n",
      "{'class_weight': {1: 60}, 'C': 0.3}\n",
      "0.483269551565\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred_prob_record = []\n",
    "val_pred_prob_record = []\n",
    "test_pred_prob_record = []\n",
    "for i in range(k):\n",
    "    print('i = ', i, '\\n')\n",
    "    train_val_features = np.concatenate((X_train_need[i], X_val), axis = 0)\n",
    "    train_val_labels = np.concatenate((y_train_need[i], y_val), axis = 0)\n",
    "    test_fold = np.zeros(train_val_features.shape[0])\n",
    "    test_fold[:X_train_need[i].shape[0]] = -1\n",
    "    ps = PredefinedSplit(test_fold = test_fold)\n",
    "\n",
    "    model = GridSearchCV(estimator=LogisticRegression(), param_grid=params, \n",
    "                         scoring=my_scoring, n_jobs=-1, cv=ps, verbose=0)\n",
    "    model.fit(train_val_features, train_val_labels)\n",
    "    print(model.best_params_ )\n",
    "    print(model.best_score_ )\n",
    "    train_pr = model.predict_proba(X_train)[:, 1]\n",
    "    val_pr = model.predict_proba(X_val)[:, 1]\n",
    "    test_pr = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    utils.model_key_performance(train_pr, y_train)\n",
    "    utils.model_key_performance(val_pr, y_val)\n",
    "    utils.model_key_performance(test_pr, y_test)\n",
    "    print('\\n')\n",
    "    \n",
    "    train_pred_prob_record.append(train_pr)\n",
    "    val_pred_prob_record.append(val_pr)\n",
    "    test_pred_prob_record.append(test_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr0 = LogisticRegression(C=1, class_weight={1:50})\n",
    "# lr0.fit(X_train_need[0], y_train_need[0])\n",
    "# train_pr = lr0.predict_proba(X_train)[:, 1]\n",
    "# val_pr = lr0.predict_proba(X_val)[:, 1]\n",
    "# test_pr = lr0.predict_proba(X_test)[:, 1]\n",
    "# utils.model_key_performance(train_pr, y_train)\n",
    "# utils.model_key_performance(val_pr, y_val)\n",
    "# utils.model_key_performance(test_pr, y_test)\n",
    "# train_pred_prob_record.append(train_pr)\n",
    "# val_pred_prob_record.append(val_pr)\n",
    "# test_pred_prob_record.append(test_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ensum = np.array(train_pred_prob_record).T\n",
    "val_ensum = np.array(val_pred_prob_record).T\n",
    "test_ensum = np.array(test_pred_prob_record).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58499, 7)\n",
      "(58499,)\n"
     ]
    }
   ],
   "source": [
    "print(train_ensum.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80224286718265125, 0.50595770508561211)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bagging\n",
    "bagging_train_prob = np.mean(train_ensum, axis = 1)\n",
    "bagging_val_prob = np.mean(val_ensum, axis = 1)\n",
    "bagging_test_prob = np.mean(test_ensum, axis = 1)\n",
    "#result\n",
    "utils.model_key_performance(bagging_train_prob, y_train)\n",
    "utils.model_key_performance(bagging_val_prob, y_val)\n",
    "utils.model_key_performance(bagging_test_prob, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_params = [i/10 for i in range(1, 10)] + [i for i in range(1, 10, 1)] + [i for i in range(10, 100, 10)]\n",
    "cw_params = [i for i in range(1, 10, 1)] + [i for i in range(10, 100, 10)]\n",
    "params = {\n",
    "    'C': C_params,\n",
    "    'class_weight': [{1:w} for w in cw_params],\n",
    "}\n",
    "\n",
    "train_val_features = np.concatenate((train_ensum, val_ensum), axis = 0)\n",
    "train_val_labels = np.concatenate((y_train, y_val), axis = 0)\n",
    "test_fold = np.zeros(train_val_features.shape[0])\n",
    "test_fold[:train_ensum.shape[0]] = -1\n",
    "ps = PredefinedSplit(test_fold = test_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68776, 7)\n",
      "(68776,)\n"
     ]
    }
   ],
   "source": [
    "print(train_val_features.shape)\n",
    "print(train_val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': {1: 20}, 'C': 0.6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.80921025610602015, 0.50909970428242857)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacking\n",
    "lr_stack = GridSearchCV(estimator=LogisticRegression(), param_grid=params, \n",
    "                         scoring=my_scoring, n_jobs=-1, cv=ps, verbose=0)\n",
    "lr_stack.fit(train_val_features, train_val_labels)\n",
    "print(lr_stack.best_params_ )\n",
    "\n",
    "lr_stack_train_pred_prob = lr_stack.predict_proba(train_ensum)[:, 1]\n",
    "lr_stack_val__pred_prob = lr_stack.predict_proba(val_ensum)[:, 1]\n",
    "lr_stack_test_pred_prob = lr_stack.predict_proba(test_ensum)[:, 1]\n",
    "utils.model_key_performance(lr_stack_train_pred_prob, y_train)\n",
    "utils.model_key_performance(lr_stack_val__pred_prob, y_val)\n",
    "utils.model_key_performance(lr_stack_test_pred_prob, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02478268,  0.08053617,  0.41711721, ...,  0.169334  ,\n",
       "        0.15065305,  0.02493949])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_stack_test_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6955, 3237],\n",
       "       [  17,   69]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_label_need = []\n",
    "for x in lr_stack_test_pred_prob:\n",
    "    if x < 0.13:\n",
    "        y_test_label_need.append(0)\n",
    "    else:\n",
    "        y_test_label_need.append(1)\n",
    "confusion_matrix(y_test, y_test_label_need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
